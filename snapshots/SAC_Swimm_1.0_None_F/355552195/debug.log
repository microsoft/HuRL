2021-05-21 23:38:00 | [online_train] Logging to ../results/data/local/experiment/shortrl/hp_tuning/SAC_Swimm_1.0_None_F/355552195
2021-05-21 23:38:02 | [online_train] Obtaining samples...
2021-05-21 23:38:53 | [online_train] epoch #0 | Saving snapshot...
2021-05-21 23:38:53 | [online_train] epoch #0 | Saved
2021-05-21 23:38:53 | [online_train] epoch #0 | Time 50.36 s
2021-05-21 23:38:53 | [online_train] epoch #0 | EpochTime 50.36 s
----------------------------------  ------------
AlphaTemperature/mean                  0.605261
Average/TrainAverageReturn           -18.8809
Evaluation/AverageDiscountedReturn    21.313
Evaluation/AverageReturn              27.4642
Evaluation/Iteration                   0
Evaluation/MaxReturn                  34.8078
Evaluation/MinReturn                  17.7893
Evaluation/NumEpisodes                10
Evaluation/StdReturn                   5.10477
Evaluation/TerminationRate             0
Policy/Loss                          -12.631
QF/Qf1Loss                             0.0838952
QF/Qf2Loss                             0.0863084
ReplayBuffer/buffer_size            4000
ShortRL/Discount0                      0.999
ShortRL/GuidanceDiscount               0.999
ShortRL/Lambda                         1
ShortRL/MaxHeuristic                   0
ShortRL/MeanHeuristic                  0
ShortRL/MinHeuristic                   0
ShortRL/RewardBias                    -0.0188785
ShortRL/RewardScale                    0.121376
ShortRL/StdHeuristic                   0
TotalEnvSteps                       4000
----------------------------------  ------------
2021-05-21 23:39:40 | [online_train] epoch #1 | Saving snapshot...
2021-05-21 23:39:40 | [online_train] epoch #1 | Saved
2021-05-21 23:39:40 | [online_train] epoch #1 | Time 97.69 s
2021-05-21 23:39:40 | [online_train] epoch #1 | EpochTime 47.33 s
----------------------------------  ------------
AlphaTemperature/mean                  0.380526
Average/TrainAverageReturn            -5.98581
Evaluation/AverageDiscountedReturn    24.852
Evaluation/AverageReturn              26.8561
Evaluation/Iteration                   1
Evaluation/MaxReturn                  29.9899
Evaluation/MinReturn                  23.6976
Evaluation/NumEpisodes                10
Evaluation/StdReturn                   2.10304
Evaluation/TerminationRate             0
Policy/Loss                          -18.2401
QF/Qf1Loss                             0.202023
QF/Qf2Loss                             0.206569
ReplayBuffer/buffer_size            8000
ShortRL/Discount0                      0.999
ShortRL/GuidanceDiscount               0.999
ShortRL/Lambda                         1
ShortRL/MaxHeuristic                   0
ShortRL/MeanHeuristic                  0
ShortRL/MinHeuristic                   0
ShortRL/RewardBias                    -0.0059609
ShortRL/RewardScale                    0.362084
ShortRL/StdHeuristic                   0
TotalEnvSteps                       8000
----------------------------------  ------------
2021-05-21 23:40:27 | [online_train] epoch #2 | Saving snapshot...
2021-05-21 23:40:27 | [online_train] epoch #2 | Saved
2021-05-21 23:40:27 | [online_train] epoch #2 | Time 144.99 s
2021-05-21 23:40:27 | [online_train] epoch #2 | EpochTime 47.29 s
----------------------------------  -------------
AlphaTemperature/mean                   0.232617
Average/TrainAverageReturn              4.22877
Evaluation/AverageDiscountedReturn     34.9878
Evaluation/AverageReturn               41.7045
Evaluation/Iteration                    2
Evaluation/MaxReturn                   44.7666
Evaluation/MinReturn                   38.9993
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    1.96077
Evaluation/TerminationRate              0
Policy/Loss                           -21.0174
QF/Qf1Loss                              0.0936387
QF/Qf2Loss                              0.0969885
ReplayBuffer/buffer_size            12000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                     -0.0059609
ShortRL/RewardScale                     0.362084
ShortRL/StdHeuristic                    0
TotalEnvSteps                       12000
----------------------------------  -------------
2021-05-21 23:41:15 | [online_train] epoch #3 | Saving snapshot...
2021-05-21 23:41:15 | [online_train] epoch #3 | Saved
2021-05-21 23:41:15 | [online_train] epoch #3 | Time 192.63 s
2021-05-21 23:41:15 | [online_train] epoch #3 | EpochTime 47.64 s
----------------------------------  -------------
AlphaTemperature/mean                   0.143604
Average/TrainAverageReturn              7.62693
Evaluation/AverageDiscountedReturn     36.0936
Evaluation/AverageReturn               42.7526
Evaluation/Iteration                    3
Evaluation/MaxReturn                   46.8547
Evaluation/MinReturn                   37.1692
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    3.41769
Evaluation/TerminationRate              0
Policy/Loss                           -23.1369
QF/Qf1Loss                              0.0572055
QF/Qf2Loss                              0.0582053
ReplayBuffer/buffer_size            16000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                     -0.0059609
ShortRL/RewardScale                     0.362084
ShortRL/StdHeuristic                    0
TotalEnvSteps                       16000
----------------------------------  -------------
2021-05-21 23:42:11 | [online_train] epoch #4 | Saving snapshot...
2021-05-21 23:42:11 | [online_train] epoch #4 | Saved
2021-05-21 23:42:11 | [online_train] epoch #4 | Time 248.22 s
2021-05-21 23:42:11 | [online_train] epoch #4 | EpochTime 55.58 s
----------------------------------  -------------
AlphaTemperature/mean                   0.0881687
Average/TrainAverageReturn             11.2804
Evaluation/AverageDiscountedReturn     29.3111
Evaluation/AverageReturn               31.3534
Evaluation/Iteration                    4
Evaluation/MaxReturn                   35.223
Evaluation/MinReturn                   27.3283
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    2.48146
Evaluation/TerminationRate              0
Policy/Loss                           -25.2897
QF/Qf1Loss                              0.0754193
QF/Qf2Loss                              0.0634155
ReplayBuffer/buffer_size            20000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                     -0.0059609
ShortRL/RewardScale                     0.362084
ShortRL/StdHeuristic                    0
TotalEnvSteps                       20000
----------------------------------  -------------
2021-05-21 23:42:58 | [online_train] epoch #5 | Saving snapshot...
2021-05-21 23:42:58 | [online_train] epoch #5 | Saved
2021-05-21 23:42:58 | [online_train] epoch #5 | Time 295.46 s
2021-05-21 23:42:58 | [online_train] epoch #5 | EpochTime 47.23 s
----------------------------------  -------------
AlphaTemperature/mean                   0.0550272
Average/TrainAverageReturn             15.1638
Evaluation/AverageDiscountedReturn     35.1906
Evaluation/AverageReturn               40.5722
Evaluation/Iteration                    5
Evaluation/MaxReturn                   45.8117
Evaluation/MinReturn                   37.1026
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    2.40567
Evaluation/TerminationRate              0
Policy/Loss                           -25.4353
QF/Qf1Loss                              0.0328575
QF/Qf2Loss                              0.034939
ReplayBuffer/buffer_size            24000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                     -0.0059609
ShortRL/RewardScale                     0.362084
ShortRL/StdHeuristic                    0
TotalEnvSteps                       24000
----------------------------------  -------------
2021-05-21 23:43:45 | [online_train] epoch #6 | Saving snapshot...
2021-05-21 23:43:45 | [online_train] epoch #6 | Saved
2021-05-21 23:43:45 | [online_train] epoch #6 | Time 343.07 s
2021-05-21 23:43:45 | [online_train] epoch #6 | EpochTime 47.61 s
----------------------------------  -------------
AlphaTemperature/mean                   0.0349008
Average/TrainAverageReturn             17.6751
Evaluation/AverageDiscountedReturn     32.7534
Evaluation/AverageReturn               37.9942
Evaluation/Iteration                    6
Evaluation/MaxReturn                   41.7351
Evaluation/MinReturn                   34.7577
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    2.24885
Evaluation/TerminationRate              0
Policy/Loss                           -27.1928
QF/Qf1Loss                              0.0339314
QF/Qf2Loss                              0.0343581
ReplayBuffer/buffer_size            28000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                     -0.0059609
ShortRL/RewardScale                     0.362084
ShortRL/StdHeuristic                    0
TotalEnvSteps                       28000
----------------------------------  -------------
2021-05-21 23:44:33 | [online_train] epoch #7 | Saving snapshot...
2021-05-21 23:44:33 | [online_train] epoch #7 | Saved
2021-05-21 23:44:33 | [online_train] epoch #7 | Time 390.72 s
2021-05-21 23:44:33 | [online_train] epoch #7 | EpochTime 47.65 s
----------------------------------  -------------
AlphaTemperature/mean                   0.0225428
Average/TrainAverageReturn             19.3415
Evaluation/AverageDiscountedReturn     36.2608
Evaluation/AverageReturn               41.7317
Evaluation/Iteration                    7
Evaluation/MaxReturn                   45.0349
Evaluation/MinReturn                   38.278
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    2.09628
Evaluation/TerminationRate              0
Policy/Loss                           -26.0552
QF/Qf1Loss                              0.0185753
QF/Qf2Loss                              0.0174327
ReplayBuffer/buffer_size            32000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                     -0.0059609
ShortRL/RewardScale                     0.362084
ShortRL/StdHeuristic                    0
TotalEnvSteps                       32000
----------------------------------  -------------
2021-05-21 23:45:20 | [online_train] epoch #8 | Saving snapshot...
2021-05-21 23:45:21 | [online_train] epoch #8 | Saved
2021-05-21 23:45:21 | [online_train] epoch #8 | Time 438.09 s
2021-05-21 23:45:21 | [online_train] epoch #8 | EpochTime 47.36 s
----------------------------------  -------------
AlphaTemperature/mean                   0.0148055
Average/TrainAverageReturn             20.5867
Evaluation/AverageDiscountedReturn     38.4637
Evaluation/AverageReturn               45.7198
Evaluation/Iteration                    8
Evaluation/MaxReturn                   50.8462
Evaluation/MinReturn                   40.3826
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    3.17801
Evaluation/TerminationRate              0
Policy/Loss                           -25.6548
QF/Qf1Loss                              0.0201264
QF/Qf2Loss                              0.0191344
ReplayBuffer/buffer_size            36000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                     -0.0059609
ShortRL/RewardScale                     0.362084
ShortRL/StdHeuristic                    0
TotalEnvSteps                       36000
----------------------------------  -------------
2021-05-21 23:46:08 | [online_train] epoch #9 | Saving snapshot...
2021-05-21 23:46:08 | [online_train] epoch #9 | Saved
2021-05-21 23:46:08 | [online_train] epoch #9 | Time 485.30 s
2021-05-21 23:46:08 | [online_train] epoch #9 | EpochTime 47.20 s
----------------------------------  -------------
AlphaTemperature/mean                   0.0147241
Average/TrainAverageReturn             21.8181
Evaluation/AverageDiscountedReturn     16.6211
Evaluation/AverageReturn               22.0019
Evaluation/Iteration                    9
Evaluation/MaxReturn                   54.5293
Evaluation/MinReturn                  -22.8876
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                   24.1961
Evaluation/TerminationRate              0
Policy/Loss                           -27.9277
QF/Qf1Loss                              0.0199212
QF/Qf2Loss                              0.0176304
ReplayBuffer/buffer_size            40000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                     -0.0059609
ShortRL/RewardScale                     0.362084
ShortRL/StdHeuristic                    0
TotalEnvSteps                       40000
----------------------------------  -------------
2021-05-21 23:46:55 | [online_train] epoch #10 | Saving snapshot...
2021-05-21 23:46:55 | [online_train] epoch #10 | Saved
2021-05-21 23:46:55 | [online_train] epoch #10 | Time 532.89 s
2021-05-21 23:46:55 | [online_train] epoch #10 | EpochTime 47.58 s
----------------------------------  -------------
AlphaTemperature/mean                   0.0112533
Average/TrainAverageReturn             21.4916
Evaluation/AverageDiscountedReturn     35.4302
Evaluation/AverageReturn               43.5259
Evaluation/Iteration                   10
Evaluation/MaxReturn                   48.2891
Evaluation/MinReturn                   37.625
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    3.65643
Evaluation/TerminationRate              0
Policy/Loss                           -31.2598
QF/Qf1Loss                              0.0249716
QF/Qf2Loss                              0.028488
ReplayBuffer/buffer_size            44000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0216136
ShortRL/RewardScale                     0.401059
ShortRL/StdHeuristic                    0
TotalEnvSteps                       44000
----------------------------------  -------------
2021-05-21 23:47:45 | [online_train] epoch #11 | Saving snapshot...
2021-05-21 23:47:45 | [online_train] epoch #11 | Saved
2021-05-21 23:47:45 | [online_train] epoch #11 | Time 582.30 s
2021-05-21 23:47:45 | [online_train] epoch #11 | EpochTime 49.40 s
----------------------------------  --------------
AlphaTemperature/mean                   0.00767741
Average/TrainAverageReturn             22.5459
Evaluation/AverageDiscountedReturn      2.83546
Evaluation/AverageReturn               -0.353587
Evaluation/Iteration                   11
Evaluation/MaxReturn                   23.5231
Evaluation/MinReturn                  -19.9354
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                   11.294
Evaluation/TerminationRate              0
Policy/Loss                           -32.1917
QF/Qf1Loss                              0.0244108
QF/Qf2Loss                              0.0347315
ReplayBuffer/buffer_size            48000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0216136
ShortRL/RewardScale                     0.401059
ShortRL/StdHeuristic                    0
TotalEnvSteps                       48000
----------------------------------  --------------
2021-05-21 23:48:32 | [online_train] epoch #12 | Saving snapshot...
2021-05-21 23:48:32 | [online_train] epoch #12 | Saved
2021-05-21 23:48:32 | [online_train] epoch #12 | Time 629.52 s
2021-05-21 23:48:32 | [online_train] epoch #12 | EpochTime 47.22 s
----------------------------------  -------------
AlphaTemperature/mean                   0.011101
Average/TrainAverageReturn             21.1787
Evaluation/AverageDiscountedReturn      3.86716
Evaluation/AverageReturn                2.90964
Evaluation/Iteration                   12
Evaluation/MaxReturn                   19.3939
Evaluation/MinReturn                  -19.1577
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                   11.582
Evaluation/TerminationRate              0
Policy/Loss                           -33.886
QF/Qf1Loss                              0.0262565
QF/Qf2Loss                              0.0380172
ReplayBuffer/buffer_size            52000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0216136
ShortRL/RewardScale                     0.401059
ShortRL/StdHeuristic                    0
TotalEnvSteps                       52000
----------------------------------  -------------
2021-05-21 23:49:19 | [online_train] epoch #13 | Saving snapshot...
2021-05-21 23:49:19 | [online_train] epoch #13 | Saved
2021-05-21 23:49:19 | [online_train] epoch #13 | Time 676.86 s
2021-05-21 23:49:19 | [online_train] epoch #13 | EpochTime 47.33 s
----------------------------------  -------------
AlphaTemperature/mean                   0.0120419
Average/TrainAverageReturn             20.5784
Evaluation/AverageDiscountedReturn     30.7094
Evaluation/AverageReturn               32.9021
Evaluation/Iteration                   13
Evaluation/MaxReturn                   45.0804
Evaluation/MinReturn                   25.6082
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    5.95497
Evaluation/TerminationRate              0
Policy/Loss                           -39.6796
QF/Qf1Loss                              0.0237728
QF/Qf2Loss                              0.0227834
ReplayBuffer/buffer_size            56000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0216136
ShortRL/RewardScale                     0.401059
ShortRL/StdHeuristic                    0
TotalEnvSteps                       56000
----------------------------------  -------------
2021-05-21 23:50:06 | [online_train] epoch #14 | Saving snapshot...
2021-05-21 23:50:06 | [online_train] epoch #14 | Saved
2021-05-21 23:50:06 | [online_train] epoch #14 | Time 723.47 s
2021-05-21 23:50:06 | [online_train] epoch #14 | EpochTime 46.60 s
----------------------------------  -------------
AlphaTemperature/mean                   0.0108246
Average/TrainAverageReturn             21.3198
Evaluation/AverageDiscountedReturn     -8.48885
Evaluation/AverageReturn              -11.6191
Evaluation/Iteration                   14
Evaluation/MaxReturn                   23.5554
Evaluation/MinReturn                  -23.3269
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                   14.6242
Evaluation/TerminationRate              0
Policy/Loss                           -40.0585
QF/Qf1Loss                              0.0226777
QF/Qf2Loss                              0.018116
ReplayBuffer/buffer_size            60000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0214045
ShortRL/RewardScale                     0.412331
ShortRL/StdHeuristic                    0
TotalEnvSteps                       60000
----------------------------------  -------------
2021-05-21 23:50:53 | [online_train] epoch #15 | Saving snapshot...
2021-05-21 23:50:53 | [online_train] epoch #15 | Saved
2021-05-21 23:50:53 | [online_train] epoch #15 | Time 770.80 s
2021-05-21 23:50:53 | [online_train] epoch #15 | EpochTime 47.33 s
----------------------------------  --------------
AlphaTemperature/mean                   0.00901643
Average/TrainAverageReturn             20.6211
Evaluation/AverageDiscountedReturn     34.6042
Evaluation/AverageReturn               45.7971
Evaluation/Iteration                   15
Evaluation/MaxReturn                   50.2806
Evaluation/MinReturn                   35.0397
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    4.93478
Evaluation/TerminationRate              0
Policy/Loss                           -41.8813
QF/Qf1Loss                              0.0144969
QF/Qf2Loss                              0.0160782
ReplayBuffer/buffer_size            64000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0214045
ShortRL/RewardScale                     0.412331
ShortRL/StdHeuristic                    0
TotalEnvSteps                       64000
----------------------------------  --------------
2021-05-21 23:51:41 | [online_train] epoch #16 | Saving snapshot...
2021-05-21 23:51:41 | [online_train] epoch #16 | Saved
2021-05-21 23:51:41 | [online_train] epoch #16 | Time 818.13 s
2021-05-21 23:51:41 | [online_train] epoch #16 | EpochTime 47.33 s
----------------------------------  --------------
AlphaTemperature/mean                   0.00766035
Average/TrainAverageReturn             21.8501
Evaluation/AverageDiscountedReturn     21.4347
Evaluation/AverageReturn               23.69
Evaluation/Iteration                   16
Evaluation/MaxReturn                   26.3613
Evaluation/MinReturn                   19.1005
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    2.47088
Evaluation/TerminationRate              0
Policy/Loss                           -42.8656
QF/Qf1Loss                              0.0104036
QF/Qf2Loss                              0.0109622
ReplayBuffer/buffer_size            68000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0214045
ShortRL/RewardScale                     0.412331
ShortRL/StdHeuristic                    0
TotalEnvSteps                       68000
----------------------------------  --------------
2021-05-21 23:52:28 | [online_train] epoch #17 | Saving snapshot...
2021-05-21 23:52:28 | [online_train] epoch #17 | Saved
2021-05-21 23:52:28 | [online_train] epoch #17 | Time 865.48 s
2021-05-21 23:52:28 | [online_train] epoch #17 | EpochTime 47.34 s
----------------------------------  --------------
AlphaTemperature/mean                   0.00549736
Average/TrainAverageReturn             22.0528
Evaluation/AverageDiscountedReturn     39.3031
Evaluation/AverageReturn               45.3909
Evaluation/Iteration                   17
Evaluation/MaxReturn                   49.4315
Evaluation/MinReturn                   41.4453
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    2.55055
Evaluation/TerminationRate              0
Policy/Loss                           -43.2354
QF/Qf1Loss                              0.0109378
QF/Qf2Loss                              0.00960653
ReplayBuffer/buffer_size            72000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0214045
ShortRL/RewardScale                     0.412331
ShortRL/StdHeuristic                    0
TotalEnvSteps                       72000
----------------------------------  --------------
2021-05-21 23:53:16 | [online_train] epoch #18 | Saving snapshot...
2021-05-21 23:53:16 | [online_train] epoch #18 | Saved
2021-05-21 23:53:16 | [online_train] epoch #18 | Time 913.12 s
2021-05-21 23:53:16 | [online_train] epoch #18 | EpochTime 47.63 s
----------------------------------  --------------
AlphaTemperature/mean                   0.00454489
Average/TrainAverageReturn             22.8666
Evaluation/AverageDiscountedReturn     30.5242
Evaluation/AverageReturn               34.6223
Evaluation/Iteration                   18
Evaluation/MaxReturn                   36.9232
Evaluation/MinReturn                   32.8534
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    1.23534
Evaluation/TerminationRate              0
Policy/Loss                           -42.5067
QF/Qf1Loss                              0.0207596
QF/Qf2Loss                              0.0198719
ReplayBuffer/buffer_size            76000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0214045
ShortRL/RewardScale                     0.412331
ShortRL/StdHeuristic                    0
TotalEnvSteps                       76000
----------------------------------  --------------
2021-05-21 23:54:03 | [online_train] epoch #19 | Saving snapshot...
2021-05-21 23:54:03 | [online_train] epoch #19 | Saved
2021-05-21 23:54:03 | [online_train] epoch #19 | Time 960.30 s
2021-05-21 23:54:03 | [online_train] epoch #19 | EpochTime 47.17 s
----------------------------------  -------------
AlphaTemperature/mean                   0.0057626
Average/TrainAverageReturn             23.006
Evaluation/AverageDiscountedReturn     11.9837
Evaluation/AverageReturn               12.3081
Evaluation/Iteration                   19
Evaluation/MaxReturn                   19.8152
Evaluation/MinReturn                    7.57105
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    3.30599
Evaluation/TerminationRate              0
Policy/Loss                           -42.6163
QF/Qf1Loss                              0.0129659
QF/Qf2Loss                              0.0140956
ReplayBuffer/buffer_size            80000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0214045
ShortRL/RewardScale                     0.412331
ShortRL/StdHeuristic                    0
TotalEnvSteps                       80000
----------------------------------  -------------
2021-05-21 23:54:50 | [online_train] epoch #20 | Saving snapshot...
2021-05-21 23:54:50 | [online_train] epoch #20 | Saved
2021-05-21 23:54:50 | [online_train] epoch #20 | Time 1007.77 s
2021-05-21 23:54:50 | [online_train] epoch #20 | EpochTime 47.46 s
----------------------------------  -------------
AlphaTemperature/mean                   0.0095435
Average/TrainAverageReturn             22.5531
Evaluation/AverageDiscountedReturn     16.6822
Evaluation/AverageReturn               21.0719
Evaluation/Iteration                   20
Evaluation/MaxReturn                   35.2434
Evaluation/MinReturn                    9.48199
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    6.91485
Evaluation/TerminationRate              0
Policy/Loss                           -45.1972
QF/Qf1Loss                              0.0110454
QF/Qf2Loss                              0.0164806
ReplayBuffer/buffer_size            84000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0214045
ShortRL/RewardScale                     0.412331
ShortRL/StdHeuristic                    0
TotalEnvSteps                       84000
----------------------------------  -------------
2021-05-21 23:55:37 | [online_train] epoch #21 | Saving snapshot...
2021-05-21 23:55:37 | [online_train] epoch #21 | Saved
2021-05-21 23:55:37 | [online_train] epoch #21 | Time 1054.14 s
2021-05-21 23:55:37 | [online_train] epoch #21 | EpochTime 46.37 s
----------------------------------  --------------
AlphaTemperature/mean                   0.00750208
Average/TrainAverageReturn             22.073
Evaluation/AverageDiscountedReturn     42.4036
Evaluation/AverageReturn               48.4172
Evaluation/Iteration                   21
Evaluation/MaxReturn                   51.5942
Evaluation/MinReturn                   45.3177
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    1.7509
Evaluation/TerminationRate              0
Policy/Loss                           -47.2701
QF/Qf1Loss                              0.0111827
QF/Qf2Loss                              0.0230516
ReplayBuffer/buffer_size            88000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0214045
ShortRL/RewardScale                     0.412331
ShortRL/StdHeuristic                    0
TotalEnvSteps                       88000
----------------------------------  --------------
2021-05-21 23:56:23 | [online_train] epoch #22 | Saving snapshot...
2021-05-21 23:56:23 | [online_train] epoch #22 | Saved
2021-05-21 23:56:23 | [online_train] epoch #22 | Time 1100.57 s
2021-05-21 23:56:23 | [online_train] epoch #22 | EpochTime 46.43 s
----------------------------------  --------------
AlphaTemperature/mean                   0.00935681
Average/TrainAverageReturn             22.248
Evaluation/AverageDiscountedReturn     14.129
Evaluation/AverageReturn               15.0989
Evaluation/Iteration                   22
Evaluation/MaxReturn                   17.0197
Evaluation/MinReturn                   13.2031
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    1.35706
Evaluation/TerminationRate              0
Policy/Loss                           -48.6706
QF/Qf1Loss                              0.014855
QF/Qf2Loss                              0.0117379
ReplayBuffer/buffer_size            92000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0214045
ShortRL/RewardScale                     0.412331
ShortRL/StdHeuristic                    0
TotalEnvSteps                       92000
----------------------------------  --------------
2021-05-21 23:57:10 | [online_train] epoch #23 | Saving snapshot...
2021-05-21 23:57:10 | [online_train] epoch #23 | Saved
2021-05-21 23:57:10 | [online_train] epoch #23 | Time 1147.23 s
2021-05-21 23:57:10 | [online_train] epoch #23 | EpochTime 46.65 s
----------------------------------  --------------
AlphaTemperature/mean                   0.00714775
Average/TrainAverageReturn             22.1967
Evaluation/AverageDiscountedReturn     27.3056
Evaluation/AverageReturn               16.9482
Evaluation/Iteration                   23
Evaluation/MaxReturn                   18.9467
Evaluation/MinReturn                   15.412
Evaluation/NumEpisodes                 10
Evaluation/StdReturn                    1.03905
Evaluation/TerminationRate              0
Policy/Loss                           -47.7387
QF/Qf1Loss                              0.0151722
QF/Qf2Loss                              0.0119758
ReplayBuffer/buffer_size            96000
ShortRL/Discount0                       0.999
ShortRL/GuidanceDiscount                0.999
ShortRL/Lambda                          1
ShortRL/MaxHeuristic                    0
ShortRL/MeanHeuristic                   0
ShortRL/MinHeuristic                    0
ShortRL/RewardBias                      0.0214045
ShortRL/RewardScale                     0.412331
ShortRL/StdHeuristic                    0
TotalEnvSteps                       96000
----------------------------------  --------------
2021-05-21 23:57:56 | [online_train] epoch #24 | Saving snapshot...
2021-05-21 23:57:56 | [online_train] epoch #24 | Saved
2021-05-21 23:57:56 | [online_train] epoch #24 | Time 1193.72 s
2021-05-21 23:57:56 | [online_train] epoch #24 | EpochTime 46.48 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00541289
Average/TrainAverageReturn              22.767
Evaluation/AverageDiscountedReturn      24.3296
Evaluation/AverageReturn                27.2809
Evaluation/Iteration                    24
Evaluation/MaxReturn                    28.635
Evaluation/MinReturn                    26.2928
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.899381
Evaluation/TerminationRate               0
Policy/Loss                            -49.8084
QF/Qf1Loss                               0.0104088
QF/Qf2Loss                               0.0132829
ReplayBuffer/buffer_size            100000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       100000
----------------------------------  ---------------
2021-05-21 23:58:44 | [online_train] epoch #25 | Saving snapshot...
2021-05-21 23:58:44 | [online_train] epoch #25 | Saved
2021-05-21 23:58:44 | [online_train] epoch #25 | Time 1241.24 s
2021-05-21 23:58:44 | [online_train] epoch #25 | EpochTime 47.51 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00670222
Average/TrainAverageReturn              22.8953
Evaluation/AverageDiscountedReturn      25.7104
Evaluation/AverageReturn                27.8296
Evaluation/Iteration                    25
Evaluation/MaxReturn                    29.085
Evaluation/MinReturn                    26.041
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.844126
Evaluation/TerminationRate               0
Policy/Loss                            -50.1972
QF/Qf1Loss                               0.00665996
QF/Qf2Loss                               0.00682581
ReplayBuffer/buffer_size            104000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       104000
----------------------------------  ---------------
2021-05-21 23:59:30 | [online_train] epoch #26 | Saving snapshot...
2021-05-21 23:59:30 | [online_train] epoch #26 | Saved
2021-05-21 23:59:30 | [online_train] epoch #26 | Time 1287.79 s
2021-05-21 23:59:30 | [online_train] epoch #26 | EpochTime 46.54 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00832629
Average/TrainAverageReturn              23.0788
Evaluation/AverageDiscountedReturn      34.3312
Evaluation/AverageReturn                41.7328
Evaluation/Iteration                    26
Evaluation/MaxReturn                    53.8089
Evaluation/MinReturn                     9.5877
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                    11.7904
Evaluation/TerminationRate               0
Policy/Loss                            -50.6016
QF/Qf1Loss                               0.00592233
QF/Qf2Loss                               0.0124731
ReplayBuffer/buffer_size            108000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       108000
----------------------------------  ---------------
2021-05-22 00:00:17 | [online_train] epoch #27 | Saving snapshot...
2021-05-22 00:00:17 | [online_train] epoch #27 | Saved
2021-05-22 00:00:17 | [online_train] epoch #27 | Time 1335.01 s
2021-05-22 00:00:17 | [online_train] epoch #27 | EpochTime 47.22 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00959144
Average/TrainAverageReturn              23.6567
Evaluation/AverageDiscountedReturn      36.3808
Evaluation/AverageReturn                39.2207
Evaluation/Iteration                    27
Evaluation/MaxReturn                    40.6319
Evaluation/MinReturn                    37.5727
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.89466
Evaluation/TerminationRate               0
Policy/Loss                            -50.2815
QF/Qf1Loss                               0.0198477
QF/Qf2Loss                               0.0211073
ReplayBuffer/buffer_size            112000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       112000
----------------------------------  ---------------
2021-05-22 00:01:28 | [online_train] epoch #28 | Saving snapshot...
2021-05-22 00:01:28 | [online_train] epoch #28 | Saved
2021-05-22 00:01:28 | [online_train] epoch #28 | Time 1405.55 s
2021-05-22 00:01:28 | [online_train] epoch #28 | EpochTime 70.53 s
----------------------------------  --------------
AlphaTemperature/mean                    0.0110992
Average/TrainAverageReturn              25.5171
Evaluation/AverageDiscountedReturn      -0.456572
Evaluation/AverageReturn                -0.595224
Evaluation/Iteration                    28
Evaluation/MaxReturn                    20.2196
Evaluation/MinReturn                   -15.3778
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                    12.4693
Evaluation/TerminationRate               0
Policy/Loss                            -54.0253
QF/Qf1Loss                               0.0214078
QF/Qf2Loss                               0.0188259
ReplayBuffer/buffer_size            116000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       116000
----------------------------------  --------------
2021-05-22 00:02:15 | [online_train] epoch #29 | Saving snapshot...
2021-05-22 00:02:15 | [online_train] epoch #29 | Saved
2021-05-22 00:02:15 | [online_train] epoch #29 | Time 1452.65 s
2021-05-22 00:02:15 | [online_train] epoch #29 | EpochTime 47.10 s
----------------------------------  --------------
AlphaTemperature/mean                    0.0124253
Average/TrainAverageReturn              24.7942
Evaluation/AverageDiscountedReturn      24.6518
Evaluation/AverageReturn                27.8249
Evaluation/Iteration                    29
Evaluation/MaxReturn                    30.0021
Evaluation/MinReturn                    24.1304
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.55985
Evaluation/TerminationRate               0
Policy/Loss                            -53.6504
QF/Qf1Loss                               0.0113913
QF/Qf2Loss                               0.0137556
ReplayBuffer/buffer_size            120000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       120000
----------------------------------  --------------
2021-05-22 00:03:02 | [online_train] epoch #30 | Saving snapshot...
2021-05-22 00:03:02 | [online_train] epoch #30 | Saved
2021-05-22 00:03:02 | [online_train] epoch #30 | Time 1499.50 s
2021-05-22 00:03:02 | [online_train] epoch #30 | EpochTime 46.84 s
----------------------------------  --------------
AlphaTemperature/mean                    0.0107373
Average/TrainAverageReturn              26.2421
Evaluation/AverageDiscountedReturn      32.1601
Evaluation/AverageReturn                36.0209
Evaluation/Iteration                    30
Evaluation/MaxReturn                    37.5998
Evaluation/MinReturn                    34.3767
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.27343
Evaluation/TerminationRate               0
Policy/Loss                            -56.8895
QF/Qf1Loss                               0.0211073
QF/Qf2Loss                               0.0127783
ReplayBuffer/buffer_size            124000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       124000
----------------------------------  --------------
2021-05-22 00:03:49 | [online_train] epoch #31 | Saving snapshot...
2021-05-22 00:03:49 | [online_train] epoch #31 | Saved
2021-05-22 00:03:49 | [online_train] epoch #31 | Time 1546.26 s
2021-05-22 00:03:49 | [online_train] epoch #31 | EpochTime 46.75 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00658478
Average/TrainAverageReturn              27.2066
Evaluation/AverageDiscountedReturn      -0.618392
Evaluation/AverageReturn                -2.54193
Evaluation/Iteration                    31
Evaluation/MaxReturn                     0.954609
Evaluation/MinReturn                   -10.4
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.73754
Evaluation/TerminationRate               0
Policy/Loss                            -57.2368
QF/Qf1Loss                               0.0113143
QF/Qf2Loss                               0.00697011
ReplayBuffer/buffer_size            128000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       128000
----------------------------------  ---------------
2021-05-22 00:04:35 | [online_train] epoch #32 | Saving snapshot...
2021-05-22 00:04:35 | [online_train] epoch #32 | Saved
2021-05-22 00:04:35 | [online_train] epoch #32 | Time 1592.77 s
2021-05-22 00:04:35 | [online_train] epoch #32 | EpochTime 46.50 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00490231
Average/TrainAverageReturn              26.9832
Evaluation/AverageDiscountedReturn       0.708175
Evaluation/AverageReturn                 2.32389
Evaluation/Iteration                    32
Evaluation/MaxReturn                    54.9408
Evaluation/MinReturn                   -13.4796
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                    19.7344
Evaluation/TerminationRate               0
Policy/Loss                            -57.0084
QF/Qf1Loss                               0.0090122
QF/Qf2Loss                               0.00948359
ReplayBuffer/buffer_size            132000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       132000
----------------------------------  ---------------
2021-05-22 00:05:22 | [online_train] epoch #33 | Saving snapshot...
2021-05-22 00:05:22 | [online_train] epoch #33 | Saved
2021-05-22 00:05:22 | [online_train] epoch #33 | Time 1639.42 s
2021-05-22 00:05:22 | [online_train] epoch #33 | EpochTime 46.64 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00878657
Average/TrainAverageReturn              26.8304
Evaluation/AverageDiscountedReturn      -1.82685
Evaluation/AverageReturn                -2.13273
Evaluation/Iteration                    33
Evaluation/MaxReturn                     7.40052
Evaluation/MinReturn                   -10.0861
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     5.88449
Evaluation/TerminationRate               0
Policy/Loss                            -58.9013
QF/Qf1Loss                               0.0148622
QF/Qf2Loss                               0.0132546
ReplayBuffer/buffer_size            136000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       136000
----------------------------------  ---------------
2021-05-22 00:06:09 | [online_train] epoch #34 | Saving snapshot...
2021-05-22 00:06:09 | [online_train] epoch #34 | Saved
2021-05-22 00:06:09 | [online_train] epoch #34 | Time 1686.15 s
2021-05-22 00:06:09 | [online_train] epoch #34 | EpochTime 46.73 s
----------------------------------  --------------
AlphaTemperature/mean                    0.0127066
Average/TrainAverageReturn              25.9526
Evaluation/AverageDiscountedReturn      -1.99625
Evaluation/AverageReturn                -2.65956
Evaluation/Iteration                    34
Evaluation/MaxReturn                    11.3891
Evaluation/MinReturn                   -21.0682
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                    10.6973
Evaluation/TerminationRate               0
Policy/Loss                            -62.4134
QF/Qf1Loss                               0.0163417
QF/Qf2Loss                               0.0175223
ReplayBuffer/buffer_size            140000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       140000
----------------------------------  --------------
2021-05-22 00:06:55 | [online_train] epoch #35 | Saving snapshot...
2021-05-22 00:06:55 | [online_train] epoch #35 | Saved
2021-05-22 00:06:55 | [online_train] epoch #35 | Time 1732.51 s
2021-05-22 00:06:55 | [online_train] epoch #35 | EpochTime 46.35 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00926696
Average/TrainAverageReturn              24.7095
Evaluation/AverageDiscountedReturn       0.0684131
Evaluation/AverageReturn                -0.189445
Evaluation/Iteration                    35
Evaluation/MaxReturn                    25.8579
Evaluation/MinReturn                   -26.2151
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                    19.5725
Evaluation/TerminationRate               0
Policy/Loss                            -62.7728
QF/Qf1Loss                               0.0183089
QF/Qf2Loss                               0.018543
ReplayBuffer/buffer_size            144000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       144000
----------------------------------  ---------------
2021-05-22 00:07:41 | [online_train] epoch #36 | Saving snapshot...
2021-05-22 00:07:41 | [online_train] epoch #36 | Saved
2021-05-22 00:07:41 | [online_train] epoch #36 | Time 1778.84 s
2021-05-22 00:07:41 | [online_train] epoch #36 | EpochTime 46.32 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00792036
Average/TrainAverageReturn              23.9038
Evaluation/AverageDiscountedReturn      38.985
Evaluation/AverageReturn                44.202
Evaluation/Iteration                    36
Evaluation/MaxReturn                    51.6508
Evaluation/MinReturn                    -8.00417
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                    17.4543
Evaluation/TerminationRate               0
Policy/Loss                            -62.1054
QF/Qf1Loss                               0.00947438
QF/Qf2Loss                               0.0103439
ReplayBuffer/buffer_size            148000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       148000
----------------------------------  ---------------
2021-05-22 00:08:28 | [online_train] epoch #37 | Saving snapshot...
2021-05-22 00:08:28 | [online_train] epoch #37 | Saved
2021-05-22 00:08:28 | [online_train] epoch #37 | Time 1825.63 s
2021-05-22 00:08:28 | [online_train] epoch #37 | EpochTime 46.79 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00624072
Average/TrainAverageReturn              24.0523
Evaluation/AverageDiscountedReturn      16.5791
Evaluation/AverageReturn                17.0715
Evaluation/Iteration                    37
Evaluation/MaxReturn                    18.4705
Evaluation/MinReturn                    15.5222
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.91466
Evaluation/TerminationRate               0
Policy/Loss                            -64.429
QF/Qf1Loss                               0.00472521
QF/Qf2Loss                               0.00554085
ReplayBuffer/buffer_size            152000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       152000
----------------------------------  ---------------
2021-05-22 00:09:15 | [online_train] epoch #38 | Saving snapshot...
2021-05-22 00:09:15 | [online_train] epoch #38 | Saved
2021-05-22 00:09:15 | [online_train] epoch #38 | Time 1872.69 s
2021-05-22 00:09:15 | [online_train] epoch #38 | EpochTime 47.05 s
----------------------------------  --------------
AlphaTemperature/mean                    0.0118953
Average/TrainAverageReturn              23.6887
Evaluation/AverageDiscountedReturn      81.3655
Evaluation/AverageReturn               130.318
Evaluation/Iteration                    38
Evaluation/MaxReturn                   139.136
Evaluation/MinReturn                   123.482
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     5.17312
Evaluation/TerminationRate               0
Policy/Loss                            -67.4222
QF/Qf1Loss                               0.0201848
QF/Qf2Loss                               0.0176692
ReplayBuffer/buffer_size            156000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       156000
----------------------------------  --------------
2021-05-22 00:10:02 | [online_train] epoch #39 | Saving snapshot...
2021-05-22 00:10:02 | [online_train] epoch #39 | Saved
2021-05-22 00:10:02 | [online_train] epoch #39 | Time 1919.38 s
2021-05-22 00:10:02 | [online_train] epoch #39 | EpochTime 46.69 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0123674
Average/TrainAverageReturn              26.7335
Evaluation/AverageDiscountedReturn      39.6291
Evaluation/AverageReturn                44.1883
Evaluation/Iteration                    39
Evaluation/MaxReturn                    45.9322
Evaluation/MinReturn                    42.8237
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.959537
Evaluation/TerminationRate               0
Policy/Loss                            -67.1115
QF/Qf1Loss                               0.0145839
QF/Qf2Loss                               0.00861695
ReplayBuffer/buffer_size            160000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       160000
----------------------------------  ---------------
2021-05-22 00:10:49 | [online_train] epoch #40 | Saving snapshot...
2021-05-22 00:10:49 | [online_train] epoch #40 | Saved
2021-05-22 00:10:49 | [online_train] epoch #40 | Time 1966.27 s
2021-05-22 00:10:49 | [online_train] epoch #40 | EpochTime 46.88 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0137292
Average/TrainAverageReturn              27.3299
Evaluation/AverageDiscountedReturn      35.9697
Evaluation/AverageReturn                37.8408
Evaluation/Iteration                    40
Evaluation/MaxReturn                    38.9211
Evaluation/MinReturn                    36.3964
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.735529
Evaluation/TerminationRate               0
Policy/Loss                            -69.551
QF/Qf1Loss                               0.00848752
QF/Qf2Loss                               0.00817778
ReplayBuffer/buffer_size            164000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       164000
----------------------------------  ---------------
2021-05-22 00:11:35 | [online_train] epoch #41 | Saving snapshot...
2021-05-22 00:11:35 | [online_train] epoch #41 | Saved
2021-05-22 00:11:35 | [online_train] epoch #41 | Time 2012.32 s
2021-05-22 00:11:35 | [online_train] epoch #41 | EpochTime 46.04 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00756383
Average/TrainAverageReturn              27.4639
Evaluation/AverageDiscountedReturn      16.0071
Evaluation/AverageReturn                15.2657
Evaluation/Iteration                    41
Evaluation/MaxReturn                    27.4114
Evaluation/MinReturn                     2.83764
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                    11.5161
Evaluation/TerminationRate               0
Policy/Loss                            -69.4121
QF/Qf1Loss                               0.013486
QF/Qf2Loss                               0.0160921
ReplayBuffer/buffer_size            168000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       168000
----------------------------------  ---------------
2021-05-22 00:12:21 | [online_train] epoch #42 | Saving snapshot...
2021-05-22 00:12:21 | [online_train] epoch #42 | Saved
2021-05-22 00:12:21 | [online_train] epoch #42 | Time 2059.02 s
2021-05-22 00:12:21 | [online_train] epoch #42 | EpochTime 46.70 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00582185
Average/TrainAverageReturn              27.9185
Evaluation/AverageDiscountedReturn      76.0552
Evaluation/AverageReturn               113.322
Evaluation/Iteration                    42
Evaluation/MaxReturn                   122.546
Evaluation/MinReturn                   107.83
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     5.13955
Evaluation/TerminationRate               0
Policy/Loss                            -68.1624
QF/Qf1Loss                               0.00687577
QF/Qf2Loss                               0.00961661
ReplayBuffer/buffer_size            172000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0214045
ShortRL/RewardScale                      0.412331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       172000
----------------------------------  ---------------
2021-05-22 00:13:14 | [online_train] epoch #43 | Saving snapshot...
2021-05-22 00:13:14 | [online_train] epoch #43 | Saved
2021-05-22 00:13:14 | [online_train] epoch #43 | Time 2112.04 s
2021-05-22 00:13:14 | [online_train] epoch #43 | EpochTime 53.01 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00529846
Average/TrainAverageReturn              31.103
Evaluation/AverageDiscountedReturn      31.9817
Evaluation/AverageReturn                41.7397
Evaluation/Iteration                    43
Evaluation/MaxReturn                    44.7236
Evaluation/MinReturn                    37.4163
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.00393
Evaluation/TerminationRate               0
Policy/Loss                            -71.3641
QF/Qf1Loss                               0.00954545
QF/Qf2Loss                               0.0114154
ReplayBuffer/buffer_size            176000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0281487
ShortRL/RewardScale                      0.438765
ShortRL/StdHeuristic                     0
TotalEnvSteps                       176000
----------------------------------  ---------------
2021-05-22 00:14:01 | [online_train] epoch #44 | Saving snapshot...
2021-05-22 00:14:01 | [online_train] epoch #44 | Saved
2021-05-22 00:14:01 | [online_train] epoch #44 | Time 2158.55 s
2021-05-22 00:14:01 | [online_train] epoch #44 | EpochTime 46.51 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00488204
Average/TrainAverageReturn              31.1128
Evaluation/AverageDiscountedReturn      58.5512
Evaluation/AverageReturn                87.1486
Evaluation/Iteration                    44
Evaluation/MaxReturn                    91.0605
Evaluation/MinReturn                    83.3086
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.86288
Evaluation/TerminationRate               0
Policy/Loss                            -70.6072
QF/Qf1Loss                               0.0153668
QF/Qf2Loss                               0.0172905
ReplayBuffer/buffer_size            180000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0281487
ShortRL/RewardScale                      0.438765
ShortRL/StdHeuristic                     0
TotalEnvSteps                       180000
----------------------------------  ---------------
2021-05-22 00:14:47 | [online_train] epoch #45 | Saving snapshot...
2021-05-22 00:14:47 | [online_train] epoch #45 | Saved
2021-05-22 00:14:47 | [online_train] epoch #45 | Time 2205.08 s
2021-05-22 00:14:47 | [online_train] epoch #45 | EpochTime 46.52 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00742138
Average/TrainAverageReturn              32.0104
Evaluation/AverageDiscountedReturn      17.9154
Evaluation/AverageReturn                27.0994
Evaluation/Iteration                    45
Evaluation/MaxReturn                    37.5538
Evaluation/MinReturn                     9.67316
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     9.60362
Evaluation/TerminationRate               0
Policy/Loss                            -70.8417
QF/Qf1Loss                               0.00740905
QF/Qf2Loss                               0.00842461
ReplayBuffer/buffer_size            184000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0281487
ShortRL/RewardScale                      0.438765
ShortRL/StdHeuristic                     0
TotalEnvSteps                       184000
----------------------------------  ---------------
2021-05-22 00:15:35 | [online_train] epoch #46 | Saving snapshot...
2021-05-22 00:15:35 | [online_train] epoch #46 | Saved
2021-05-22 00:15:35 | [online_train] epoch #46 | Time 2252.41 s
2021-05-22 00:15:35 | [online_train] epoch #46 | EpochTime 47.33 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00800831
Average/TrainAverageReturn              31.4855
Evaluation/AverageDiscountedReturn      89.5711
Evaluation/AverageReturn               127.97
Evaluation/Iteration                    46
Evaluation/MaxReturn                   140.323
Evaluation/MinReturn                   109.893
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                    11.4927
Evaluation/TerminationRate               0
Policy/Loss                            -71.5006
QF/Qf1Loss                               0.0109891
QF/Qf2Loss                               0.0105754
ReplayBuffer/buffer_size            188000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0281487
ShortRL/RewardScale                      0.438765
ShortRL/StdHeuristic                     0
TotalEnvSteps                       188000
----------------------------------  ---------------
2021-05-22 00:16:21 | [online_train] epoch #47 | Saving snapshot...
2021-05-22 00:16:21 | [online_train] epoch #47 | Saved
2021-05-22 00:16:21 | [online_train] epoch #47 | Time 2298.99 s
2021-05-22 00:16:21 | [online_train] epoch #47 | EpochTime 46.57 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00805867
Average/TrainAverageReturn              35.1654
Evaluation/AverageDiscountedReturn      96.2426
Evaluation/AverageReturn               140.465
Evaluation/Iteration                    47
Evaluation/MaxReturn                   160.607
Evaluation/MinReturn                   135.519
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     7.43798
Evaluation/TerminationRate               0
Policy/Loss                            -73.5706
QF/Qf1Loss                               0.0109027
QF/Qf2Loss                               0.0113521
ReplayBuffer/buffer_size            192000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0308457
ShortRL/RewardScale                      0.464363
ShortRL/StdHeuristic                     0
TotalEnvSteps                       192000
----------------------------------  ---------------
2021-05-22 00:17:08 | [online_train] epoch #48 | Saving snapshot...
2021-05-22 00:17:08 | [online_train] epoch #48 | Saved
2021-05-22 00:17:08 | [online_train] epoch #48 | Time 2345.43 s
2021-05-22 00:17:08 | [online_train] epoch #48 | EpochTime 46.43 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00576045
Average/TrainAverageReturn              38.5395
Evaluation/AverageDiscountedReturn      60.5694
Evaluation/AverageReturn                84.4775
Evaluation/Iteration                    48
Evaluation/MaxReturn                    85.6431
Evaluation/MinReturn                    82.8483
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.797562
Evaluation/TerminationRate               0
Policy/Loss                            -74.8086
QF/Qf1Loss                               0.00933683
QF/Qf2Loss                               0.0120987
ReplayBuffer/buffer_size            196000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0332659
ShortRL/RewardScale                      0.504027
ShortRL/StdHeuristic                     0
TotalEnvSteps                       196000
----------------------------------  ---------------
2021-05-22 00:17:57 | [online_train] epoch #49 | Saving snapshot...
2021-05-22 00:17:57 | [online_train] epoch #49 | Saved
2021-05-22 00:17:57 | [online_train] epoch #49 | Time 2394.49 s
2021-05-22 00:17:57 | [online_train] epoch #49 | EpochTime 49.05 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00742073
Average/TrainAverageReturn              41.4086
Evaluation/AverageDiscountedReturn      77.4471
Evaluation/AverageReturn               120.272
Evaluation/Iteration                    49
Evaluation/MaxReturn                   131.528
Evaluation/MinReturn                   112.659
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     4.51924
Evaluation/TerminationRate               0
Policy/Loss                            -73.0963
QF/Qf1Loss                               0.00850341
QF/Qf2Loss                               0.00879556
ReplayBuffer/buffer_size            200000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0349937
ShortRL/RewardScale                      0.513331
ShortRL/StdHeuristic                     0
TotalEnvSteps                       200000
----------------------------------  ---------------
2021-05-22 00:18:43 | [online_train] epoch #50 | Saving snapshot...
2021-05-22 00:18:43 | [online_train] epoch #50 | Saved
2021-05-22 00:18:43 | [online_train] epoch #50 | Time 2441.02 s
2021-05-22 00:18:43 | [online_train] epoch #50 | EpochTime 46.52 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00919566
Average/TrainAverageReturn              44.9071
Evaluation/AverageDiscountedReturn      78.8481
Evaluation/AverageReturn               113.768
Evaluation/Iteration                    50
Evaluation/MaxReturn                   120.073
Evaluation/MinReturn                   107.165
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.91472
Evaluation/TerminationRate               0
Policy/Loss                            -75.5256
QF/Qf1Loss                               0.0120542
QF/Qf2Loss                               0.0103142
ReplayBuffer/buffer_size            204000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.036799
ShortRL/RewardScale                      0.515746
ShortRL/StdHeuristic                     0
TotalEnvSteps                       204000
----------------------------------  ---------------
2021-05-22 00:19:30 | [online_train] epoch #51 | Saving snapshot...
2021-05-22 00:19:30 | [online_train] epoch #51 | Saved
2021-05-22 00:19:30 | [online_train] epoch #51 | Time 2487.65 s
2021-05-22 00:19:30 | [online_train] epoch #51 | EpochTime 46.62 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00685931
Average/TrainAverageReturn              47.7891
Evaluation/AverageDiscountedReturn      73.792
Evaluation/AverageReturn                91.9281
Evaluation/Iteration                    51
Evaluation/MaxReturn                   108.851
Evaluation/MinReturn                    85.8176
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     8.4288
Evaluation/TerminationRate               0
Policy/Loss                            -75.3821
QF/Qf1Loss                               0.0118719
QF/Qf2Loss                               0.00956773
ReplayBuffer/buffer_size            208000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0381094
ShortRL/RewardScale                      0.541291
ShortRL/StdHeuristic                     0
TotalEnvSteps                       208000
----------------------------------  ---------------
2021-05-22 00:20:19 | [online_train] epoch #52 | Saving snapshot...
2021-05-22 00:20:19 | [online_train] epoch #52 | Saved
2021-05-22 00:20:19 | [online_train] epoch #52 | Time 2537.07 s
2021-05-22 00:20:19 | [online_train] epoch #52 | EpochTime 49.42 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00560062
Average/TrainAverageReturn              50.8715
Evaluation/AverageDiscountedReturn      20.3867
Evaluation/AverageReturn                25.5122
Evaluation/Iteration                    52
Evaluation/MaxReturn                    43.2491
Evaluation/MinReturn                   -20.4774
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                    25.9725
Evaluation/TerminationRate               0
Policy/Loss                            -73.9668
QF/Qf1Loss                               0.0108207
QF/Qf2Loss                               0.0119486
ReplayBuffer/buffer_size            212000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0397907
ShortRL/RewardScale                      0.554141
ShortRL/StdHeuristic                     0
TotalEnvSteps                       212000
----------------------------------  ---------------
2021-05-22 00:21:08 | [online_train] epoch #53 | Saving snapshot...
2021-05-22 00:21:08 | [online_train] epoch #53 | Saved
2021-05-22 00:21:08 | [online_train] epoch #53 | Time 2585.17 s
2021-05-22 00:21:08 | [online_train] epoch #53 | EpochTime 48.09 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00780227
Average/TrainAverageReturn              54.8541
Evaluation/AverageDiscountedReturn      94.3037
Evaluation/AverageReturn               146.972
Evaluation/Iteration                    53
Evaluation/MaxReturn                   156.593
Evaluation/MinReturn                   138.248
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     6.95599
Evaluation/TerminationRate               0
Policy/Loss                            -75.6816
QF/Qf1Loss                               0.0152917
QF/Qf2Loss                               0.0136637
ReplayBuffer/buffer_size            216000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0418605
ShortRL/RewardScale                      0.570816
ShortRL/StdHeuristic                     0
TotalEnvSteps                       216000
----------------------------------  ---------------
2021-05-22 00:21:56 | [online_train] epoch #54 | Saving snapshot...
2021-05-22 00:21:56 | [online_train] epoch #54 | Saved
2021-05-22 00:21:56 | [online_train] epoch #54 | Time 2633.85 s
2021-05-22 00:21:56 | [online_train] epoch #54 | EpochTime 48.67 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00985872
Average/TrainAverageReturn              57.2296
Evaluation/AverageDiscountedReturn     102.546
Evaluation/AverageReturn               157.279
Evaluation/Iteration                    54
Evaluation/MaxReturn                   158.904
Evaluation/MinReturn                   156.282
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.829053
Evaluation/TerminationRate               0
Policy/Loss                            -76.5641
QF/Qf1Loss                               0.00534728
QF/Qf2Loss                               0.00924653
ReplayBuffer/buffer_size            220000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0431919
ShortRL/RewardScale                      0.573045
ShortRL/StdHeuristic                     0
TotalEnvSteps                       220000
----------------------------------  ---------------
2021-05-22 00:22:48 | [online_train] epoch #55 | Saving snapshot...
2021-05-22 00:22:48 | [online_train] epoch #55 | Saved
2021-05-22 00:22:48 | [online_train] epoch #55 | Time 2685.95 s
2021-05-22 00:22:48 | [online_train] epoch #55 | EpochTime 52.09 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00658883
Average/TrainAverageReturn              61.4597
Evaluation/AverageDiscountedReturn     101.63
Evaluation/AverageReturn               157.757
Evaluation/Iteration                    55
Evaluation/MaxReturn                   173.641
Evaluation/MinReturn                   143.344
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     9.58611
Evaluation/TerminationRate               0
Policy/Loss                            -77.8544
QF/Qf1Loss                               0.00560359
QF/Qf2Loss                               0.00636174
ReplayBuffer/buffer_size            224000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0453765
ShortRL/RewardScale                      0.585117
ShortRL/StdHeuristic                     0
TotalEnvSteps                       224000
----------------------------------  ---------------
2021-05-22 00:23:39 | [online_train] epoch #56 | Saving snapshot...
2021-05-22 00:23:39 | [online_train] epoch #56 | Saved
2021-05-22 00:23:39 | [online_train] epoch #56 | Time 2736.46 s
2021-05-22 00:23:39 | [online_train] epoch #56 | EpochTime 50.50 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00521345
Average/TrainAverageReturn              65.5385
Evaluation/AverageDiscountedReturn     104.503
Evaluation/AverageReturn               162.796
Evaluation/Iteration                    56
Evaluation/MaxReturn                   173.127
Evaluation/MinReturn                   149.9
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     7.50556
Evaluation/TerminationRate               0
Policy/Loss                            -78.229
QF/Qf1Loss                               0.0136653
QF/Qf2Loss                               0.0233141
ReplayBuffer/buffer_size            228000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0474292
ShortRL/RewardScale                      0.605173
ShortRL/StdHeuristic                     0
TotalEnvSteps                       228000
----------------------------------  ---------------
2021-05-22 00:24:26 | [online_train] epoch #57 | Saving snapshot...
2021-05-22 00:24:26 | [online_train] epoch #57 | Saved
2021-05-22 00:24:26 | [online_train] epoch #57 | Time 2783.87 s
2021-05-22 00:24:26 | [online_train] epoch #57 | EpochTime 47.41 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00736243
Average/TrainAverageReturn              69.418
Evaluation/AverageDiscountedReturn      37.2559
Evaluation/AverageReturn                47.0273
Evaluation/Iteration                    57
Evaluation/MaxReturn                    57.232
Evaluation/MinReturn                    40.0693
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     5.34385
Evaluation/TerminationRate               0
Policy/Loss                            -78.3246
QF/Qf1Loss                               0.0104222
QF/Qf2Loss                               0.00968008
ReplayBuffer/buffer_size            232000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0495157
ShortRL/RewardScale                      0.619585
ShortRL/StdHeuristic                     0
TotalEnvSteps                       232000
----------------------------------  ---------------
2021-05-22 00:25:14 | [online_train] epoch #58 | Saving snapshot...
2021-05-22 00:25:14 | [online_train] epoch #58 | Saved
2021-05-22 00:25:14 | [online_train] epoch #58 | Time 2831.13 s
2021-05-22 00:25:14 | [online_train] epoch #58 | EpochTime 47.26 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00883929
Average/TrainAverageReturn              69.0231
Evaluation/AverageDiscountedReturn      41.0123
Evaluation/AverageReturn                48.3962
Evaluation/Iteration                    58
Evaluation/MaxReturn                    52.0081
Evaluation/MinReturn                    45.9288
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.58282
Evaluation/TerminationRate               0
Policy/Loss                            -81.8152
QF/Qf1Loss                               0.00832314
QF/Qf2Loss                               0.0082522
ReplayBuffer/buffer_size            236000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0495157
ShortRL/RewardScale                      0.619585
ShortRL/StdHeuristic                     0
TotalEnvSteps                       236000
----------------------------------  ---------------
2021-05-22 00:26:00 | [online_train] epoch #59 | Saving snapshot...
2021-05-22 00:26:00 | [online_train] epoch #59 | Saved
2021-05-22 00:26:00 | [online_train] epoch #59 | Time 2877.74 s
2021-05-22 00:26:00 | [online_train] epoch #59 | EpochTime 46.60 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00856214
Average/TrainAverageReturn              70.9319
Evaluation/AverageDiscountedReturn     123.413
Evaluation/AverageReturn               200.848
Evaluation/Iteration                    59
Evaluation/MaxReturn                   202.782
Evaluation/MinReturn                   197.931
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.40852
Evaluation/TerminationRate               0
Policy/Loss                            -81.0696
QF/Qf1Loss                               0.0104712
QF/Qf2Loss                               0.0220334
ReplayBuffer/buffer_size            240000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0495157
ShortRL/RewardScale                      0.619585
ShortRL/StdHeuristic                     0
TotalEnvSteps                       240000
----------------------------------  ---------------
2021-05-22 00:26:47 | [online_train] epoch #60 | Saving snapshot...
2021-05-22 00:26:47 | [online_train] epoch #60 | Saved
2021-05-22 00:26:47 | [online_train] epoch #60 | Time 2924.73 s
2021-05-22 00:26:47 | [online_train] epoch #60 | EpochTime 46.99 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0076593
Average/TrainAverageReturn              76.1357
Evaluation/AverageDiscountedReturn     108.233
Evaluation/AverageReturn               163.004
Evaluation/Iteration                    60
Evaluation/MaxReturn                   165.687
Evaluation/MinReturn                   160.902
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.38017
Evaluation/TerminationRate               0
Policy/Loss                            -83.4571
QF/Qf1Loss                               0.00776325
QF/Qf2Loss                               0.00690925
ReplayBuffer/buffer_size            244000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0524436
ShortRL/RewardScale                      0.641061
ShortRL/StdHeuristic                     0
TotalEnvSteps                       244000
----------------------------------  ---------------
2021-05-22 00:27:34 | [online_train] epoch #61 | Saving snapshot...
2021-05-22 00:27:34 | [online_train] epoch #61 | Saved
2021-05-22 00:27:34 | [online_train] epoch #61 | Time 2971.23 s
2021-05-22 00:27:34 | [online_train] epoch #61 | EpochTime 46.49 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00797808
Average/TrainAverageReturn              80.6758
Evaluation/AverageDiscountedReturn     118.253
Evaluation/AverageReturn               181.93
Evaluation/Iteration                    61
Evaluation/MaxReturn                   188.008
Evaluation/MinReturn                   136.379
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                    15.1935
Evaluation/TerminationRate               0
Policy/Loss                            -84.325
QF/Qf1Loss                               0.0118629
QF/Qf2Loss                               0.0122146
ReplayBuffer/buffer_size            248000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0546175
ShortRL/RewardScale                      0.666383
ShortRL/StdHeuristic                     0
TotalEnvSteps                       248000
----------------------------------  ---------------
2021-05-22 00:28:20 | [online_train] epoch #62 | Saving snapshot...
2021-05-22 00:28:20 | [online_train] epoch #62 | Saved
2021-05-22 00:28:20 | [online_train] epoch #62 | Time 3018.07 s
2021-05-22 00:28:20 | [online_train] epoch #62 | EpochTime 46.84 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00982648
Average/TrainAverageReturn              86.6306
Evaluation/AverageDiscountedReturn     118.067
Evaluation/AverageReturn               179.769
Evaluation/Iteration                    62
Evaluation/MaxReturn                   181.051
Evaluation/MinReturn                   179.078
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.614746
Evaluation/TerminationRate               0
Policy/Loss                            -81.4604
QF/Qf1Loss                               0.00762686
QF/Qf2Loss                               0.00886433
ReplayBuffer/buffer_size            252000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.057162
ShortRL/RewardScale                      0.685475
ShortRL/StdHeuristic                     0
TotalEnvSteps                       252000
----------------------------------  ---------------
2021-05-22 00:29:07 | [online_train] epoch #63 | Saving snapshot...
2021-05-22 00:29:07 | [online_train] epoch #63 | Saved
2021-05-22 00:29:07 | [online_train] epoch #63 | Time 3064.62 s
2021-05-22 00:29:07 | [online_train] epoch #63 | EpochTime 46.55 s
----------------------------------  --------------
AlphaTemperature/mean                    0.0096813
Average/TrainAverageReturn              92.0798
Evaluation/AverageDiscountedReturn     116.411
Evaluation/AverageReturn               180.714
Evaluation/Iteration                    63
Evaluation/MaxReturn                   182.776
Evaluation/MinReturn                   177.838
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.5912
Evaluation/TerminationRate               0
Policy/Loss                            -82.4062
QF/Qf1Loss                               0.0135551
QF/Qf2Loss                               0.0390684
ReplayBuffer/buffer_size            256000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0592752
ShortRL/RewardScale                      0.700633
ShortRL/StdHeuristic                     0
TotalEnvSteps                       256000
----------------------------------  --------------
2021-05-22 00:29:54 | [online_train] epoch #64 | Saving snapshot...
2021-05-22 00:29:54 | [online_train] epoch #64 | Saved
2021-05-22 00:29:54 | [online_train] epoch #64 | Time 3111.26 s
2021-05-22 00:29:54 | [online_train] epoch #64 | EpochTime 46.63 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00945469
Average/TrainAverageReturn              97.686
Evaluation/AverageDiscountedReturn     127.527
Evaluation/AverageReturn               202.381
Evaluation/Iteration                    64
Evaluation/MaxReturn                   208.298
Evaluation/MinReturn                   196.035
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.77856
Evaluation/TerminationRate               0
Policy/Loss                            -84.5911
QF/Qf1Loss                               0.0102577
QF/Qf2Loss                               0.0116235
ReplayBuffer/buffer_size            260000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0611667
ShortRL/RewardScale                      0.714125
ShortRL/StdHeuristic                     0
TotalEnvSteps                       260000
----------------------------------  ---------------
2021-05-22 00:30:41 | [online_train] epoch #65 | Saving snapshot...
2021-05-22 00:30:41 | [online_train] epoch #65 | Saved
2021-05-22 00:30:41 | [online_train] epoch #65 | Time 3158.34 s
2021-05-22 00:30:41 | [online_train] epoch #65 | EpochTime 47.08 s
----------------------------------  --------------
AlphaTemperature/mean                    0.0101893
Average/TrainAverageReturn             104.285
Evaluation/AverageDiscountedReturn     127.374
Evaluation/AverageReturn               199.457
Evaluation/Iteration                    65
Evaluation/MaxReturn                   200.528
Evaluation/MinReturn                   198.051
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.733834
Evaluation/TerminationRate               0
Policy/Loss                            -86.0145
QF/Qf1Loss                               0.0184094
QF/Qf2Loss                               0.014646
ReplayBuffer/buffer_size            264000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0634738
ShortRL/RewardScale                      0.73009
ShortRL/StdHeuristic                     0
TotalEnvSteps                       264000
----------------------------------  --------------
2021-05-22 00:31:28 | [online_train] epoch #66 | Saving snapshot...
2021-05-22 00:31:28 | [online_train] epoch #66 | Saved
2021-05-22 00:31:28 | [online_train] epoch #66 | Time 3205.33 s
2021-05-22 00:31:28 | [online_train] epoch #66 | EpochTime 46.98 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00853977
Average/TrainAverageReturn             109.983
Evaluation/AverageDiscountedReturn     117.636
Evaluation/AverageReturn               175.717
Evaluation/Iteration                    66
Evaluation/MaxReturn                   176.721
Evaluation/MinReturn                   172.706
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.12325
Evaluation/TerminationRate               0
Policy/Loss                            -86.0964
QF/Qf1Loss                               0.0121537
QF/Qf2Loss                               0.014132
ReplayBuffer/buffer_size            268000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0654448
ShortRL/RewardScale                      0.741489
ShortRL/StdHeuristic                     0
TotalEnvSteps                       268000
----------------------------------  ---------------
2021-05-22 00:32:15 | [online_train] epoch #67 | Saving snapshot...
2021-05-22 00:32:15 | [online_train] epoch #67 | Saved
2021-05-22 00:32:15 | [online_train] epoch #67 | Time 3252.52 s
2021-05-22 00:32:15 | [online_train] epoch #67 | EpochTime 47.19 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00944576
Average/TrainAverageReturn             114.746
Evaluation/AverageDiscountedReturn     120.31
Evaluation/AverageReturn               180.201
Evaluation/Iteration                    67
Evaluation/MaxReturn                   182.282
Evaluation/MinReturn                   179.196
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.921997
Evaluation/TerminationRate               0
Policy/Loss                            -87.7099
QF/Qf1Loss                               0.00766224
QF/Qf2Loss                               0.00969323
ReplayBuffer/buffer_size            272000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0673373
ShortRL/RewardScale                      0.754416
ShortRL/StdHeuristic                     0
TotalEnvSteps                       272000
----------------------------------  ---------------
2021-05-22 00:33:02 | [online_train] epoch #68 | Saving snapshot...
2021-05-22 00:33:02 | [online_train] epoch #68 | Saved
2021-05-22 00:33:02 | [online_train] epoch #68 | Time 3299.27 s
2021-05-22 00:33:02 | [online_train] epoch #68 | EpochTime 46.75 s
----------------------------------  --------------
AlphaTemperature/mean                    0.0107881
Average/TrainAverageReturn             120.473
Evaluation/AverageDiscountedReturn     127.776
Evaluation/AverageReturn               196.275
Evaluation/Iteration                    68
Evaluation/MaxReturn                   200.547
Evaluation/MinReturn                   191.969
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.35221
Evaluation/TerminationRate               0
Policy/Loss                            -88.1245
QF/Qf1Loss                               0.0196183
QF/Qf2Loss                               0.0114328
ReplayBuffer/buffer_size            276000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0693918
ShortRL/RewardScale                      0.769642
ShortRL/StdHeuristic                     0
TotalEnvSteps                       276000
----------------------------------  --------------
2021-05-22 00:33:49 | [online_train] epoch #69 | Saving snapshot...
2021-05-22 00:33:49 | [online_train] epoch #69 | Saved
2021-05-22 00:33:49 | [online_train] epoch #69 | Time 3346.21 s
2021-05-22 00:33:49 | [online_train] epoch #69 | EpochTime 46.94 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00860988
Average/TrainAverageReturn             122.953
Evaluation/AverageDiscountedReturn     132.764
Evaluation/AverageReturn               202.29
Evaluation/Iteration                    69
Evaluation/MaxReturn                   219.307
Evaluation/MinReturn                   188.599
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                    10.1405
Evaluation/TerminationRate               0
Policy/Loss                            -89.0832
QF/Qf1Loss                               0.00791236
QF/Qf2Loss                               0.00554842
ReplayBuffer/buffer_size            280000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0715048
ShortRL/RewardScale                      0.785612
ShortRL/StdHeuristic                     0
TotalEnvSteps                       280000
----------------------------------  ---------------
2021-05-22 00:34:36 | [online_train] epoch #70 | Saving snapshot...
2021-05-22 00:34:36 | [online_train] epoch #70 | Saved
2021-05-22 00:34:36 | [online_train] epoch #70 | Time 3394.02 s
2021-05-22 00:34:36 | [online_train] epoch #70 | EpochTime 47.80 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00804793
Average/TrainAverageReturn             128.546
Evaluation/AverageDiscountedReturn     128.332
Evaluation/AverageReturn               192.995
Evaluation/Iteration                    70
Evaluation/MaxReturn                   195.653
Evaluation/MinReturn                   191.258
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.26376
Evaluation/TerminationRate               0
Policy/Loss                            -89.4579
QF/Qf1Loss                               0.0122597
QF/Qf2Loss                               0.0114038
ReplayBuffer/buffer_size            284000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0736427
ShortRL/RewardScale                      0.795776
ShortRL/StdHeuristic                     0
TotalEnvSteps                       284000
----------------------------------  ---------------
2021-05-22 00:35:24 | [online_train] epoch #71 | Saving snapshot...
2021-05-22 00:35:24 | [online_train] epoch #71 | Saved
2021-05-22 00:35:24 | [online_train] epoch #71 | Time 3441.38 s
2021-05-22 00:35:24 | [online_train] epoch #71 | EpochTime 47.36 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00958212
Average/TrainAverageReturn             133.856
Evaluation/AverageDiscountedReturn     134.784
Evaluation/AverageReturn               213.612
Evaluation/Iteration                    71
Evaluation/MaxReturn                   215.335
Evaluation/MinReturn                   211.751
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.12205
Evaluation/TerminationRate               0
Policy/Loss                            -91.0357
QF/Qf1Loss                               0.00768819
QF/Qf2Loss                               0.00896527
ReplayBuffer/buffer_size            288000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0756182
ShortRL/RewardScale                      0.808185
ShortRL/StdHeuristic                     0
TotalEnvSteps                       288000
----------------------------------  ---------------
2021-05-22 00:36:11 | [online_train] epoch #72 | Saving snapshot...
2021-05-22 00:36:11 | [online_train] epoch #72 | Saved
2021-05-22 00:36:11 | [online_train] epoch #72 | Time 3488.66 s
2021-05-22 00:36:11 | [online_train] epoch #72 | EpochTime 47.28 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00903182
Average/TrainAverageReturn             139.961
Evaluation/AverageDiscountedReturn     137.375
Evaluation/AverageReturn               214.037
Evaluation/Iteration                    72
Evaluation/MaxReturn                   224.054
Evaluation/MinReturn                   209.312
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.95659
Evaluation/TerminationRate               0
Policy/Loss                            -92.2152
QF/Qf1Loss                               0.00517953
QF/Qf2Loss                               0.00654875
ReplayBuffer/buffer_size            292000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0776034
ShortRL/RewardScale                      0.820462
ShortRL/StdHeuristic                     0
TotalEnvSteps                       292000
----------------------------------  ---------------
2021-05-22 00:36:58 | [online_train] epoch #73 | Saving snapshot...
2021-05-22 00:36:58 | [online_train] epoch #73 | Saved
2021-05-22 00:36:58 | [online_train] epoch #73 | Time 3536.03 s
2021-05-22 00:36:58 | [online_train] epoch #73 | EpochTime 47.36 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0092974
Average/TrainAverageReturn             142.951
Evaluation/AverageDiscountedReturn     121.814
Evaluation/AverageReturn               183.935
Evaluation/Iteration                    73
Evaluation/MaxReturn                   187.729
Evaluation/MinReturn                   178.089
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.89351
Evaluation/TerminationRate               0
Policy/Loss                            -91.7427
QF/Qf1Loss                               0.00647683
QF/Qf2Loss                               0.00608148
ReplayBuffer/buffer_size            296000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0794798
ShortRL/RewardScale                      0.832533
ShortRL/StdHeuristic                     0
TotalEnvSteps                       296000
----------------------------------  ---------------
2021-05-22 00:37:46 | [online_train] epoch #74 | Saving snapshot...
2021-05-22 00:37:46 | [online_train] epoch #74 | Saved
2021-05-22 00:37:46 | [online_train] epoch #74 | Time 3583.95 s
2021-05-22 00:37:46 | [online_train] epoch #74 | EpochTime 47.91 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00894832
Average/TrainAverageReturn             147.306
Evaluation/AverageDiscountedReturn     135.242
Evaluation/AverageReturn               210.978
Evaluation/Iteration                    74
Evaluation/MaxReturn                   213.615
Evaluation/MinReturn                   201.783
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.20384
Evaluation/TerminationRate               0
Policy/Loss                            -92.2234
QF/Qf1Loss                               0.0126689
QF/Qf2Loss                               0.00982312
ReplayBuffer/buffer_size            300000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0807611
ShortRL/RewardScale                      0.842613
ShortRL/StdHeuristic                     0
TotalEnvSteps                       300000
----------------------------------  ---------------
2021-05-22 00:38:35 | [online_train] epoch #75 | Saving snapshot...
2021-05-22 00:38:35 | [online_train] epoch #75 | Saved
2021-05-22 00:38:35 | [online_train] epoch #75 | Time 3632.93 s
2021-05-22 00:38:35 | [online_train] epoch #75 | EpochTime 48.97 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0088126
Average/TrainAverageReturn             152.458
Evaluation/AverageDiscountedReturn     133.67
Evaluation/AverageReturn               210.79
Evaluation/Iteration                    75
Evaluation/MaxReturn                   211.861
Evaluation/MinReturn                   209.48
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.63167
Evaluation/TerminationRate               0
Policy/Loss                            -95.0477
QF/Qf1Loss                               0.0096979
QF/Qf2Loss                               0.00527767
ReplayBuffer/buffer_size            304000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0824494
ShortRL/RewardScale                      0.849687
ShortRL/StdHeuristic                     0
TotalEnvSteps                       304000
----------------------------------  ---------------
2021-05-22 00:39:22 | [online_train] epoch #76 | Saving snapshot...
2021-05-22 00:39:22 | [online_train] epoch #76 | Saved
2021-05-22 00:39:22 | [online_train] epoch #76 | Time 3679.90 s
2021-05-22 00:39:22 | [online_train] epoch #76 | EpochTime 46.97 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00978416
Average/TrainAverageReturn             158.239
Evaluation/AverageDiscountedReturn     138.279
Evaluation/AverageReturn               218.726
Evaluation/Iteration                    76
Evaluation/MaxReturn                   219.62
Evaluation/MinReturn                   217.914
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.621085
Evaluation/TerminationRate               0
Policy/Loss                            -94.9806
QF/Qf1Loss                               0.00980506
QF/Qf2Loss                               0.0123032
ReplayBuffer/buffer_size            308000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.084208
ShortRL/RewardScale                      0.856549
ShortRL/StdHeuristic                     0
TotalEnvSteps                       308000
----------------------------------  ---------------
2021-05-22 00:41:52 | [online_train] epoch #77 | Saving snapshot...
2021-05-22 00:41:52 | [online_train] epoch #77 | Saved
2021-05-22 00:41:52 | [online_train] epoch #77 | Time 3829.57 s
2021-05-22 00:41:52 | [online_train] epoch #77 | EpochTime 149.67 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00975551
Average/TrainAverageReturn             159.918
Evaluation/AverageDiscountedReturn     127.513
Evaluation/AverageReturn               191.843
Evaluation/Iteration                    77
Evaluation/MaxReturn                   195.209
Evaluation/MinReturn                   189.644
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.69845
Evaluation/TerminationRate               0
Policy/Loss                            -94.3868
QF/Qf1Loss                               0.0118154
QF/Qf2Loss                               0.0123625
ReplayBuffer/buffer_size            312000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0857282
ShortRL/RewardScale                      0.86386
ShortRL/StdHeuristic                     0
TotalEnvSteps                       312000
----------------------------------  ---------------
2021-05-22 00:42:52 | [online_train] epoch #78 | Saving snapshot...
2021-05-22 00:42:52 | [online_train] epoch #78 | Saved
2021-05-22 00:42:52 | [online_train] epoch #78 | Time 3889.35 s
2021-05-22 00:42:52 | [online_train] epoch #78 | EpochTime 59.77 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0100216
Average/TrainAverageReturn             161.813
Evaluation/AverageDiscountedReturn     138.4
Evaluation/AverageReturn               217.911
Evaluation/Iteration                    78
Evaluation/MaxReturn                   219.611
Evaluation/MinReturn                   215.169
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.7238
Evaluation/TerminationRate               0
Policy/Loss                            -95.5998
QF/Qf1Loss                               0.00797334
QF/Qf2Loss                               0.0216031
ReplayBuffer/buffer_size            316000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0873468
ShortRL/RewardScale                      0.868998
ShortRL/StdHeuristic                     0
TotalEnvSteps                       316000
----------------------------------  ---------------
2021-05-22 00:43:49 | [online_train] epoch #79 | Saving snapshot...
2021-05-22 00:43:49 | [online_train] epoch #79 | Saved
2021-05-22 00:43:49 | [online_train] epoch #79 | Time 3946.26 s
2021-05-22 00:43:49 | [online_train] epoch #79 | EpochTime 56.91 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00933043
Average/TrainAverageReturn             165.103
Evaluation/AverageDiscountedReturn     137.882
Evaluation/AverageReturn               213.254
Evaluation/Iteration                    79
Evaluation/MaxReturn                   221.151
Evaluation/MinReturn                   204.941
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     4.91829
Evaluation/TerminationRate               0
Policy/Loss                            -96.3322
QF/Qf1Loss                               0.00853967
QF/Qf2Loss                               0.00663931
ReplayBuffer/buffer_size            320000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0891414
ShortRL/RewardScale                      0.876004
ShortRL/StdHeuristic                     0
TotalEnvSteps                       320000
----------------------------------  ---------------
2021-05-22 00:44:37 | [online_train] epoch #80 | Saving snapshot...
2021-05-22 00:44:37 | [online_train] epoch #80 | Saved
2021-05-22 00:44:37 | [online_train] epoch #80 | Time 3994.20 s
2021-05-22 00:44:37 | [online_train] epoch #80 | EpochTime 47.93 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00942958
Average/TrainAverageReturn             168.362
Evaluation/AverageDiscountedReturn     139.304
Evaluation/AverageReturn               218.491
Evaluation/Iteration                    80
Evaluation/MaxReturn                   220.447
Evaluation/MinReturn                   212.299
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.14811
Evaluation/TerminationRate               0
Policy/Loss                            -99.6857
QF/Qf1Loss                               0.010321
QF/Qf2Loss                               0.00724893
ReplayBuffer/buffer_size            324000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0909743
ShortRL/RewardScale                      0.883157
ShortRL/StdHeuristic                     0
TotalEnvSteps                       324000
----------------------------------  ---------------
2021-05-22 00:45:24 | [online_train] epoch #81 | Saving snapshot...
2021-05-22 00:45:24 | [online_train] epoch #81 | Saved
2021-05-22 00:45:24 | [online_train] epoch #81 | Time 4041.39 s
2021-05-22 00:45:24 | [online_train] epoch #81 | EpochTime 47.19 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00968195
Average/TrainAverageReturn             172.199
Evaluation/AverageDiscountedReturn     129.342
Evaluation/AverageReturn               193.202
Evaluation/Iteration                    81
Evaluation/MaxReturn                   199.468
Evaluation/MinReturn                   189.419
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.77154
Evaluation/TerminationRate               0
Policy/Loss                            -99.2921
QF/Qf1Loss                               0.00743605
QF/Qf2Loss                               0.00766322
ReplayBuffer/buffer_size            328000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0927244
ShortRL/RewardScale                      0.888487
ShortRL/StdHeuristic                     0
TotalEnvSteps                       328000
----------------------------------  ---------------
2021-05-22 00:46:12 | [online_train] epoch #82 | Saving snapshot...
2021-05-22 00:46:12 | [online_train] epoch #82 | Saved
2021-05-22 00:46:12 | [online_train] epoch #82 | Time 4089.75 s
2021-05-22 00:46:12 | [online_train] epoch #82 | EpochTime 48.35 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00916586
Average/TrainAverageReturn             174.802
Evaluation/AverageDiscountedReturn     130.978
Evaluation/AverageReturn               197.647
Evaluation/Iteration                    82
Evaluation/MaxReturn                   199.762
Evaluation/MinReturn                   193.777
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.66088
Evaluation/TerminationRate               0
Policy/Loss                            -99.7733
QF/Qf1Loss                               0.00406352
QF/Qf2Loss                               0.00578352
ReplayBuffer/buffer_size            332000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0941932
ShortRL/RewardScale                      0.893291
ShortRL/StdHeuristic                     0
TotalEnvSteps                       332000
----------------------------------  ---------------
2021-05-22 00:47:00 | [online_train] epoch #83 | Saving snapshot...
2021-05-22 00:47:00 | [online_train] epoch #83 | Saved
2021-05-22 00:47:00 | [online_train] epoch #83 | Time 4137.66 s
2021-05-22 00:47:00 | [online_train] epoch #83 | EpochTime 47.91 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00923072
Average/TrainAverageReturn             176.621
Evaluation/AverageDiscountedReturn     134.258
Evaluation/AverageReturn               210.074
Evaluation/Iteration                    83
Evaluation/MaxReturn                   211.97
Evaluation/MinReturn                   206.921
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.65793
Evaluation/TerminationRate               0
Policy/Loss                            -98.9729
QF/Qf1Loss                               0.00512046
QF/Qf2Loss                               0.0049103
ReplayBuffer/buffer_size            336000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0956044
ShortRL/RewardScale                      0.898869
ShortRL/StdHeuristic                     0
TotalEnvSteps                       336000
----------------------------------  ---------------
2021-05-22 00:47:48 | [online_train] epoch #84 | Saving snapshot...
2021-05-22 00:47:48 | [online_train] epoch #84 | Saved
2021-05-22 00:47:48 | [online_train] epoch #84 | Time 4185.13 s
2021-05-22 00:47:48 | [online_train] epoch #84 | EpochTime 47.46 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00903483
Average/TrainAverageReturn             179.707
Evaluation/AverageDiscountedReturn     136.592
Evaluation/AverageReturn               214.457
Evaluation/Iteration                    84
Evaluation/MaxReturn                   215.819
Evaluation/MinReturn                   212.936
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.868323
Evaluation/TerminationRate               0
Policy/Loss                           -101.459
QF/Qf1Loss                               0.0136946
QF/Qf2Loss                               0.014846
ReplayBuffer/buffer_size            340000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.0970543
ShortRL/RewardScale                      0.903699
ShortRL/StdHeuristic                     0
TotalEnvSteps                       340000
----------------------------------  ---------------
2021-05-22 00:48:35 | [online_train] epoch #85 | Saving snapshot...
2021-05-22 00:48:35 | [online_train] epoch #85 | Saved
2021-05-22 00:48:35 | [online_train] epoch #85 | Time 4233.03 s
2021-05-22 00:48:35 | [online_train] epoch #85 | EpochTime 47.90 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00955332
Average/TrainAverageReturn             181.656
Evaluation/AverageDiscountedReturn     131.699
Evaluation/AverageReturn               198.886
Evaluation/Iteration                    85
Evaluation/MaxReturn                   211.39
Evaluation/MinReturn                   188.869
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     8.02136
Evaluation/TerminationRate               0
Policy/Loss                           -101.776
QF/Qf1Loss                               0.00777063
QF/Qf2Loss                               0.00605389
ReplayBuffer/buffer_size            344000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.098624
ShortRL/RewardScale                      0.908513
ShortRL/StdHeuristic                     0
TotalEnvSteps                       344000
----------------------------------  ---------------
2021-05-22 00:49:22 | [online_train] epoch #86 | Saving snapshot...
2021-05-22 00:49:22 | [online_train] epoch #86 | Saved
2021-05-22 00:49:22 | [online_train] epoch #86 | Time 4280.04 s
2021-05-22 00:49:22 | [online_train] epoch #86 | EpochTime 47.00 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00931642
Average/TrainAverageReturn             183.478
Evaluation/AverageDiscountedReturn     137.62
Evaluation/AverageReturn               215.868
Evaluation/Iteration                    86
Evaluation/MaxReturn                   218.777
Evaluation/MinReturn                   211.551
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.08177
Evaluation/TerminationRate               0
Policy/Loss                           -100.392
QF/Qf1Loss                               0.00445918
QF/Qf2Loss                               0.00776612
ReplayBuffer/buffer_size            348000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.100067
ShortRL/RewardScale                      0.913602
ShortRL/StdHeuristic                     0
TotalEnvSteps                       348000
----------------------------------  ---------------
2021-05-22 00:50:11 | [online_train] epoch #87 | Saving snapshot...
2021-05-22 00:50:11 | [online_train] epoch #87 | Saved
2021-05-22 00:50:11 | [online_train] epoch #87 | Time 4328.94 s
2021-05-22 00:50:11 | [online_train] epoch #87 | EpochTime 48.90 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00919917
Average/TrainAverageReturn             184.794
Evaluation/AverageDiscountedReturn     127.464
Evaluation/AverageReturn               190.196
Evaluation/Iteration                    87
Evaluation/MaxReturn                   193.789
Evaluation/MinReturn                   188.459
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.56385
Evaluation/TerminationRate               0
Policy/Loss                           -105.111
QF/Qf1Loss                               0.0109664
QF/Qf2Loss                               0.0050018
ReplayBuffer/buffer_size            352000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.101346
ShortRL/RewardScale                      0.919202
ShortRL/StdHeuristic                     0
TotalEnvSteps                       352000
----------------------------------  ---------------
2021-05-22 00:50:59 | [online_train] epoch #88 | Saving snapshot...
2021-05-22 00:50:59 | [online_train] epoch #88 | Saved
2021-05-22 00:50:59 | [online_train] epoch #88 | Time 4376.81 s
2021-05-22 00:50:59 | [online_train] epoch #88 | EpochTime 47.86 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00899759
Average/TrainAverageReturn             189.238
Evaluation/AverageDiscountedReturn     133.025
Evaluation/AverageReturn               201.898
Evaluation/Iteration                    88
Evaluation/MaxReturn                   204.471
Evaluation/MinReturn                   198.85
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.18019
Evaluation/TerminationRate               0
Policy/Loss                           -101.915
QF/Qf1Loss                               0.00632536
QF/Qf2Loss                               0.00833353
ReplayBuffer/buffer_size            356000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.102648
ShortRL/RewardScale                      0.923767
ShortRL/StdHeuristic                     0
TotalEnvSteps                       356000
----------------------------------  ---------------
2021-05-22 00:51:46 | [online_train] epoch #89 | Saving snapshot...
2021-05-22 00:51:46 | [online_train] epoch #89 | Saved
2021-05-22 00:51:46 | [online_train] epoch #89 | Time 4423.65 s
2021-05-22 00:51:46 | [online_train] epoch #89 | EpochTime 46.83 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00893802
Average/TrainAverageReturn             193.717
Evaluation/AverageDiscountedReturn     134.871
Evaluation/AverageReturn               212.685
Evaluation/Iteration                    89
Evaluation/MaxReturn                   215.43
Evaluation/MinReturn                   208.549
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.05403
Evaluation/TerminationRate               0
Policy/Loss                           -105.109
QF/Qf1Loss                               0.00672328
QF/Qf2Loss                               0.00380082
ReplayBuffer/buffer_size            360000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.103874
ShortRL/RewardScale                      0.929428
ShortRL/StdHeuristic                     0
TotalEnvSteps                       360000
----------------------------------  ---------------
2021-05-22 00:52:33 | [online_train] epoch #90 | Saving snapshot...
2021-05-22 00:52:33 | [online_train] epoch #90 | Saved
2021-05-22 00:52:33 | [online_train] epoch #90 | Time 4470.68 s
2021-05-22 00:52:33 | [online_train] epoch #90 | EpochTime 47.03 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00913384
Average/TrainAverageReturn             194.117
Evaluation/AverageDiscountedReturn     135.686
Evaluation/AverageReturn               214.312
Evaluation/Iteration                    90
Evaluation/MaxReturn                   215.296
Evaluation/MinReturn                   212.978
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.81172
Evaluation/TerminationRate               0
Policy/Loss                           -105.001
QF/Qf1Loss                               0.00466772
QF/Qf2Loss                               0.00437691
ReplayBuffer/buffer_size            364000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.105036
ShortRL/RewardScale                      0.935142
ShortRL/StdHeuristic                     0
TotalEnvSteps                       364000
----------------------------------  ---------------
2021-05-22 00:53:21 | [online_train] epoch #91 | Saving snapshot...
2021-05-22 00:53:21 | [online_train] epoch #91 | Saved
2021-05-22 00:53:21 | [online_train] epoch #91 | Time 4518.51 s
2021-05-22 00:53:21 | [online_train] epoch #91 | EpochTime 47.82 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00899422
Average/TrainAverageReturn             195.391
Evaluation/AverageDiscountedReturn     141.294
Evaluation/AverageReturn               223.387
Evaluation/Iteration                    91
Evaluation/MaxReturn                   224.379
Evaluation/MinReturn                   222.602
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.534378
Evaluation/TerminationRate               0
Policy/Loss                           -106.156
QF/Qf1Loss                               0.00700012
QF/Qf2Loss                               0.00679936
ReplayBuffer/buffer_size            368000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.106401
ShortRL/RewardScale                      0.939372
ShortRL/StdHeuristic                     0
TotalEnvSteps                       368000
----------------------------------  ---------------
2021-05-22 00:54:08 | [online_train] epoch #92 | Saving snapshot...
2021-05-22 00:54:08 | [online_train] epoch #92 | Saved
2021-05-22 00:54:08 | [online_train] epoch #92 | Time 4565.55 s
2021-05-22 00:54:08 | [online_train] epoch #92 | EpochTime 47.03 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00892323
Average/TrainAverageReturn             195.471
Evaluation/AverageDiscountedReturn     138.894
Evaluation/AverageReturn               218.312
Evaluation/Iteration                    92
Evaluation/MaxReturn                   219.131
Evaluation/MinReturn                   217.025
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.728914
Evaluation/TerminationRate               0
Policy/Loss                           -105.367
QF/Qf1Loss                               0.00730831
QF/Qf2Loss                               0.00529777
ReplayBuffer/buffer_size            372000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.107591
ShortRL/RewardScale                      0.944914
ShortRL/StdHeuristic                     0
TotalEnvSteps                       372000
----------------------------------  ---------------
2021-05-22 00:54:55 | [online_train] epoch #93 | Saving snapshot...
2021-05-22 00:54:56 | [online_train] epoch #93 | Saved
2021-05-22 00:54:56 | [online_train] epoch #93 | Time 4613.09 s
2021-05-22 00:54:56 | [online_train] epoch #93 | EpochTime 47.53 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0094103
Average/TrainAverageReturn             196.558
Evaluation/AverageDiscountedReturn     139.333
Evaluation/AverageReturn               217.966
Evaluation/Iteration                    93
Evaluation/MaxReturn                   223.777
Evaluation/MinReturn                   209.983
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     5.02615
Evaluation/TerminationRate               0
Policy/Loss                           -108.18
QF/Qf1Loss                               0.00655365
QF/Qf2Loss                               0.0134125
ReplayBuffer/buffer_size            376000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.108887
ShortRL/RewardScale                      0.948906
ShortRL/StdHeuristic                     0
TotalEnvSteps                       376000
----------------------------------  ---------------
2021-05-22 00:55:43 | [online_train] epoch #94 | Saving snapshot...
2021-05-22 00:55:43 | [online_train] epoch #94 | Saved
2021-05-22 00:55:43 | [online_train] epoch #94 | Time 4660.22 s
2021-05-22 00:55:43 | [online_train] epoch #94 | EpochTime 47.13 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00911497
Average/TrainAverageReturn             197.864
Evaluation/AverageDiscountedReturn     134.15
Evaluation/AverageReturn               206.134
Evaluation/Iteration                    94
Evaluation/MaxReturn                   209.433
Evaluation/MinReturn                   201.174
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.96645
Evaluation/TerminationRate               0
Policy/Loss                           -109.162
QF/Qf1Loss                               0.00698289
QF/Qf2Loss                               0.00560555
ReplayBuffer/buffer_size            380000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.110125
ShortRL/RewardScale                      0.953584
ShortRL/StdHeuristic                     0
TotalEnvSteps                       380000
----------------------------------  ---------------
2021-05-22 00:56:30 | [online_train] epoch #95 | Saving snapshot...
2021-05-22 00:56:30 | [online_train] epoch #95 | Saved
2021-05-22 00:56:30 | [online_train] epoch #95 | Time 4707.65 s
2021-05-22 00:56:30 | [online_train] epoch #95 | EpochTime 47.42 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00927029
Average/TrainAverageReturn             198.394
Evaluation/AverageDiscountedReturn     136.449
Evaluation/AverageReturn               214.621
Evaluation/Iteration                    95
Evaluation/MaxReturn                   216.091
Evaluation/MinReturn                   213.093
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.912163
Evaluation/TerminationRate               0
Policy/Loss                           -108.516
QF/Qf1Loss                               0.00637037
QF/Qf2Loss                               0.00601876
ReplayBuffer/buffer_size            384000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.11139
ShortRL/RewardScale                      0.957507
ShortRL/StdHeuristic                     0
TotalEnvSteps                       384000
----------------------------------  ---------------
2021-05-22 00:57:17 | [online_train] epoch #96 | Saving snapshot...
2021-05-22 00:57:17 | [online_train] epoch #96 | Saved
2021-05-22 00:57:17 | [online_train] epoch #96 | Time 4754.80 s
2021-05-22 00:57:17 | [online_train] epoch #96 | EpochTime 47.15 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00889791
Average/TrainAverageReturn             198.889
Evaluation/AverageDiscountedReturn     135.307
Evaluation/AverageReturn               210.984
Evaluation/Iteration                    96
Evaluation/MaxReturn                   216.433
Evaluation/MinReturn                   198.067
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     5.79194
Evaluation/TerminationRate               0
Policy/Loss                           -107.597
QF/Qf1Loss                               0.00565656
QF/Qf2Loss                               0.00532891
ReplayBuffer/buffer_size            388000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.11242
ShortRL/RewardScale                      0.960644
ShortRL/StdHeuristic                     0
TotalEnvSteps                       388000
----------------------------------  ---------------
2021-05-22 00:58:05 | [online_train] epoch #97 | Saving snapshot...
2021-05-22 00:58:05 | [online_train] epoch #97 | Saved
2021-05-22 00:58:05 | [online_train] epoch #97 | Time 4802.40 s
2021-05-22 00:58:05 | [online_train] epoch #97 | EpochTime 47.59 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00886871
Average/TrainAverageReturn             199.497
Evaluation/AverageDiscountedReturn     135.843
Evaluation/AverageReturn               213.304
Evaluation/Iteration                    97
Evaluation/MaxReturn                   214.258
Evaluation/MinReturn                   211.14
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.989026
Evaluation/TerminationRate               0
Policy/Loss                           -109.907
QF/Qf1Loss                               0.00608637
QF/Qf2Loss                               0.00571554
ReplayBuffer/buffer_size            392000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.113456
ShortRL/RewardScale                      0.964019
ShortRL/StdHeuristic                     0
TotalEnvSteps                       392000
----------------------------------  ---------------
2021-05-22 00:58:52 | [online_train] epoch #98 | Saving snapshot...
2021-05-22 00:58:52 | [online_train] epoch #98 | Saved
2021-05-22 00:58:52 | [online_train] epoch #98 | Time 4849.36 s
2021-05-22 00:58:52 | [online_train] epoch #98 | EpochTime 46.95 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00898448
Average/TrainAverageReturn             199.919
Evaluation/AverageDiscountedReturn     136.486
Evaluation/AverageReturn               214.04
Evaluation/Iteration                    98
Evaluation/MaxReturn                   215.125
Evaluation/MinReturn                   212.697
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.700574
Evaluation/TerminationRate               0
Policy/Loss                           -109.731
QF/Qf1Loss                               0.00378504
QF/Qf2Loss                               0.00760328
ReplayBuffer/buffer_size            396000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.114563
ShortRL/RewardScale                      0.967047
ShortRL/StdHeuristic                     0
TotalEnvSteps                       396000
----------------------------------  ---------------
2021-05-22 00:59:39 | [online_train] epoch #99 | Saving snapshot...
2021-05-22 00:59:39 | [online_train] epoch #99 | Saved
2021-05-22 00:59:39 | [online_train] epoch #99 | Time 4896.49 s
2021-05-22 00:59:39 | [online_train] epoch #99 | EpochTime 47.12 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0090439
Average/TrainAverageReturn             200.134
Evaluation/AverageDiscountedReturn     139.142
Evaluation/AverageReturn               217.722
Evaluation/Iteration                    99
Evaluation/MaxReturn                   221.257
Evaluation/MinReturn                   212.28
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.58393
Evaluation/TerminationRate               0
Policy/Loss                           -110.972
QF/Qf1Loss                               0.00598074
QF/Qf2Loss                               0.00475223
ReplayBuffer/buffer_size            400000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.11566
ShortRL/RewardScale                      0.969665
ShortRL/StdHeuristic                     0
TotalEnvSteps                       400000
----------------------------------  ---------------
2021-05-22 01:00:51 | [online_train] epoch #100 | Saving snapshot...
2021-05-22 01:00:51 | [online_train] epoch #100 | Saved
2021-05-22 01:00:51 | [online_train] epoch #100 | Time 4968.97 s
2021-05-22 01:00:51 | [online_train] epoch #100 | EpochTime 72.47 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00922016
Average/TrainAverageReturn             200.012
Evaluation/AverageDiscountedReturn     135.766
Evaluation/AverageReturn               212.746
Evaluation/Iteration                   100
Evaluation/MaxReturn                   214.836
Evaluation/MinReturn                   207.623
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.10712
Evaluation/TerminationRate               0
Policy/Loss                           -110.383
QF/Qf1Loss                               0.00660892
QF/Qf2Loss                               0.0128049
ReplayBuffer/buffer_size            404000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.116675
ShortRL/RewardScale                      0.97359
ShortRL/StdHeuristic                     0
TotalEnvSteps                       404000
----------------------------------  ---------------
2021-05-22 01:01:39 | [online_train] epoch #101 | Saving snapshot...
2021-05-22 01:01:39 | [online_train] epoch #101 | Saved
2021-05-22 01:01:39 | [online_train] epoch #101 | Time 5016.31 s
2021-05-22 01:01:39 | [online_train] epoch #101 | EpochTime 47.34 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00895434
Average/TrainAverageReturn             200.281
Evaluation/AverageDiscountedReturn     137.471
Evaluation/AverageReturn               215.191
Evaluation/Iteration                   101
Evaluation/MaxReturn                   217.929
Evaluation/MinReturn                   202.656
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     4.23443
Evaluation/TerminationRate               0
Policy/Loss                           -112.281
QF/Qf1Loss                               0.00848721
QF/Qf2Loss                               0.00485834
ReplayBuffer/buffer_size            408000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.117734
ShortRL/RewardScale                      0.976316
ShortRL/StdHeuristic                     0
TotalEnvSteps                       408000
----------------------------------  ---------------
2021-05-22 01:02:26 | [online_train] epoch #102 | Saving snapshot...
2021-05-22 01:02:26 | [online_train] epoch #102 | Saved
2021-05-22 01:02:26 | [online_train] epoch #102 | Time 5063.61 s
2021-05-22 01:02:26 | [online_train] epoch #102 | EpochTime 47.30 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00916773
Average/TrainAverageReturn             200.269
Evaluation/AverageDiscountedReturn     129.483
Evaluation/AverageReturn               199.397
Evaluation/Iteration                   102
Evaluation/MaxReturn                   206.693
Evaluation/MinReturn                   184.41
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     6.95994
Evaluation/TerminationRate               0
Policy/Loss                           -113.054
QF/Qf1Loss                               0.0052328
QF/Qf2Loss                               0.00510902
ReplayBuffer/buffer_size            412000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.118721
ShortRL/RewardScale                      0.979702
ShortRL/StdHeuristic                     0
TotalEnvSteps                       412000
----------------------------------  ---------------
2021-05-22 01:03:13 | [online_train] epoch #103 | Saving snapshot...
2021-05-22 01:03:13 | [online_train] epoch #103 | Saved
2021-05-22 01:03:13 | [online_train] epoch #103 | Time 5110.83 s
2021-05-22 01:03:13 | [online_train] epoch #103 | EpochTime 47.22 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00906092
Average/TrainAverageReturn             200.232
Evaluation/AverageDiscountedReturn     133.895
Evaluation/AverageReturn               205.246
Evaluation/Iteration                   103
Evaluation/MaxReturn                   213.362
Evaluation/MinReturn                   193.931
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     5.9841
Evaluation/TerminationRate               0
Policy/Loss                           -113.099
QF/Qf1Loss                               0.00976599
QF/Qf2Loss                               0.0107697
ReplayBuffer/buffer_size            416000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.119638
ShortRL/RewardScale                      0.981748
ShortRL/StdHeuristic                     0
TotalEnvSteps                       416000
----------------------------------  ---------------
2021-05-22 01:04:00 | [online_train] epoch #104 | Saving snapshot...
2021-05-22 01:04:00 | [online_train] epoch #104 | Saved
2021-05-22 01:04:00 | [online_train] epoch #104 | Time 5157.57 s
2021-05-22 01:04:00 | [online_train] epoch #104 | EpochTime 46.73 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00916867
Average/TrainAverageReturn             201.7
Evaluation/AverageDiscountedReturn     134.829
Evaluation/AverageReturn               204.783
Evaluation/Iteration                   104
Evaluation/MaxReturn                   217.795
Evaluation/MinReturn                   194.197
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     7.75991
Evaluation/TerminationRate               0
Policy/Loss                           -114.993
QF/Qf1Loss                               0.00673541
QF/Qf2Loss                               0.00705179
ReplayBuffer/buffer_size            420000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.120652
ShortRL/RewardScale                      0.984429
ShortRL/StdHeuristic                     0
TotalEnvSteps                       420000
----------------------------------  ---------------
2021-05-22 01:04:47 | [online_train] epoch #105 | Saving snapshot...
2021-05-22 01:04:47 | [online_train] epoch #105 | Saved
2021-05-22 01:04:47 | [online_train] epoch #105 | Time 5205.08 s
2021-05-22 01:04:47 | [online_train] epoch #105 | EpochTime 47.50 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00947762
Average/TrainAverageReturn             202.562
Evaluation/AverageDiscountedReturn     128.536
Evaluation/AverageReturn               191.49
Evaluation/Iteration                   105
Evaluation/MaxReturn                   195.578
Evaluation/MinReturn                   189.1
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.68046
Evaluation/TerminationRate               0
Policy/Loss                           -113.967
QF/Qf1Loss                               0.00596947
QF/Qf2Loss                               0.00762684
ReplayBuffer/buffer_size            424000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.12177
ShortRL/RewardScale                      0.987621
ShortRL/StdHeuristic                     0
TotalEnvSteps                       424000
----------------------------------  ---------------
2021-05-22 01:05:35 | [online_train] epoch #106 | Saving snapshot...
2021-05-22 01:05:35 | [online_train] epoch #106 | Saved
2021-05-22 01:05:35 | [online_train] epoch #106 | Time 5252.84 s
2021-05-22 01:05:35 | [online_train] epoch #106 | EpochTime 47.75 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00918242
Average/TrainAverageReturn             202.868
Evaluation/AverageDiscountedReturn     137.538
Evaluation/AverageReturn               215.918
Evaluation/Iteration                   106
Evaluation/MaxReturn                   216.879
Evaluation/MinReturn                   213.276
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.05698
Evaluation/TerminationRate               0
Policy/Loss                           -117.223
QF/Qf1Loss                               0.00497076
QF/Qf2Loss                               0.00560934
ReplayBuffer/buffer_size            428000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.122763
ShortRL/RewardScale                      0.990547
ShortRL/StdHeuristic                     0
TotalEnvSteps                       428000
----------------------------------  ---------------
2021-05-22 01:06:22 | [online_train] epoch #107 | Saving snapshot...
2021-05-22 01:06:22 | [online_train] epoch #107 | Saved
2021-05-22 01:06:22 | [online_train] epoch #107 | Time 5299.98 s
2021-05-22 01:06:22 | [online_train] epoch #107 | EpochTime 47.14 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00919303
Average/TrainAverageReturn             203.596
Evaluation/AverageDiscountedReturn     135.925
Evaluation/AverageReturn               212.015
Evaluation/Iteration                   107
Evaluation/MaxReturn                   213.574
Evaluation/MinReturn                   210.203
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.06934
Evaluation/TerminationRate               0
Policy/Loss                           -116.693
QF/Qf1Loss                               0.00578776
QF/Qf2Loss                               0.00283523
ReplayBuffer/buffer_size            432000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.123735
ShortRL/RewardScale                      0.993599
ShortRL/StdHeuristic                     0
TotalEnvSteps                       432000
----------------------------------  ---------------
2021-05-22 01:07:10 | [online_train] epoch #108 | Saving snapshot...
2021-05-22 01:07:10 | [online_train] epoch #108 | Saved
2021-05-22 01:07:10 | [online_train] epoch #108 | Time 5347.27 s
2021-05-22 01:07:10 | [online_train] epoch #108 | EpochTime 47.28 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00901712
Average/TrainAverageReturn             203.608
Evaluation/AverageDiscountedReturn     136.968
Evaluation/AverageReturn               214.417
Evaluation/Iteration                   108
Evaluation/MaxReturn                   217.035
Evaluation/MinReturn                   208.711
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.18448
Evaluation/TerminationRate               0
Policy/Loss                           -117.48
QF/Qf1Loss                               0.00506259
QF/Qf2Loss                               0.0101658
ReplayBuffer/buffer_size            436000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.12455
ShortRL/RewardScale                      0.995979
ShortRL/StdHeuristic                     0
TotalEnvSteps                       436000
----------------------------------  ---------------
2021-05-22 01:07:57 | [online_train] epoch #109 | Saving snapshot...
2021-05-22 01:07:57 | [online_train] epoch #109 | Saved
2021-05-22 01:07:57 | [online_train] epoch #109 | Time 5394.16 s
2021-05-22 01:07:57 | [online_train] epoch #109 | EpochTime 46.89 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00841702
Average/TrainAverageReturn             203.325
Evaluation/AverageDiscountedReturn     140.088
Evaluation/AverageReturn               219.667
Evaluation/Iteration                   109
Evaluation/MaxReturn                   220.901
Evaluation/MinReturn                   216.659
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.17956
Evaluation/TerminationRate               0
Policy/Loss                           -117.055
QF/Qf1Loss                               0.00870135
QF/Qf2Loss                               0.00621033
ReplayBuffer/buffer_size            440000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.125418
ShortRL/RewardScale                      0.999276
ShortRL/StdHeuristic                     0
TotalEnvSteps                       440000
----------------------------------  ---------------
2021-05-22 01:08:44 | [online_train] epoch #110 | Saving snapshot...
2021-05-22 01:08:45 | [online_train] epoch #110 | Saved
2021-05-22 01:08:45 | [online_train] epoch #110 | Time 5442.09 s
2021-05-22 01:08:45 | [online_train] epoch #110 | EpochTime 47.92 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0082119
Average/TrainAverageReturn             202.992
Evaluation/AverageDiscountedReturn     139.688
Evaluation/AverageReturn               219.167
Evaluation/Iteration                   110
Evaluation/MaxReturn                   220.914
Evaluation/MinReturn                   217.56
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.05261
Evaluation/TerminationRate               0
Policy/Loss                           -119.133
QF/Qf1Loss                               0.00736307
QF/Qf2Loss                               0.00360244
ReplayBuffer/buffer_size            444000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.126318
ShortRL/RewardScale                      1.00247
ShortRL/StdHeuristic                     0
TotalEnvSteps                       444000
----------------------------------  ---------------
2021-05-22 01:09:32 | [online_train] epoch #111 | Saving snapshot...
2021-05-22 01:09:32 | [online_train] epoch #111 | Saved
2021-05-22 01:09:32 | [online_train] epoch #111 | Time 5489.43 s
2021-05-22 01:09:32 | [online_train] epoch #111 | EpochTime 47.34 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00811172
Average/TrainAverageReturn             202.615
Evaluation/AverageDiscountedReturn     133.42
Evaluation/AverageReturn               200.271
Evaluation/Iteration                   111
Evaluation/MaxReturn                   201.723
Evaluation/MinReturn                   198.491
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.1115
Evaluation/TerminationRate               0
Policy/Loss                           -119.881
QF/Qf1Loss                               0.0117549
QF/Qf2Loss                               0.0065324
ReplayBuffer/buffer_size            448000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.127158
ShortRL/RewardScale                      1.00489
ShortRL/StdHeuristic                     0
TotalEnvSteps                       448000
----------------------------------  ---------------
2021-05-22 01:10:20 | [online_train] epoch #112 | Saving snapshot...
2021-05-22 01:10:20 | [online_train] epoch #112 | Saved
2021-05-22 01:10:20 | [online_train] epoch #112 | Time 5537.29 s
2021-05-22 01:10:20 | [online_train] epoch #112 | EpochTime 47.86 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0085184
Average/TrainAverageReturn             203.228
Evaluation/AverageDiscountedReturn     139.26
Evaluation/AverageReturn               218.035
Evaluation/Iteration                   112
Evaluation/MaxReturn                   219.561
Evaluation/MinReturn                   216.985
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.938064
Evaluation/TerminationRate               0
Policy/Loss                           -119.69
QF/Qf1Loss                               0.00749953
QF/Qf2Loss                               0.00566908
ReplayBuffer/buffer_size            452000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.128123
ShortRL/RewardScale                      1.0085
ShortRL/StdHeuristic                     0
TotalEnvSteps                       452000
----------------------------------  ---------------
2021-05-22 01:11:07 | [online_train] epoch #113 | Saving snapshot...
2021-05-22 01:11:07 | [online_train] epoch #113 | Saved
2021-05-22 01:11:07 | [online_train] epoch #113 | Time 5584.69 s
2021-05-22 01:11:07 | [online_train] epoch #113 | EpochTime 47.40 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00849848
Average/TrainAverageReturn             203.796
Evaluation/AverageDiscountedReturn     138.324
Evaluation/AverageReturn               213.687
Evaluation/Iteration                   113
Evaluation/MaxReturn                   220.617
Evaluation/MinReturn                   209.288
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.70766
Evaluation/TerminationRate               0
Policy/Loss                           -119.521
QF/Qf1Loss                               0.00793265
QF/Qf2Loss                               0.00446766
ReplayBuffer/buffer_size            456000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.129038
ShortRL/RewardScale                      1.01184
ShortRL/StdHeuristic                     0
TotalEnvSteps                       456000
----------------------------------  ---------------
2021-05-22 01:11:55 | [online_train] epoch #114 | Saving snapshot...
2021-05-22 01:11:55 | [online_train] epoch #114 | Saved
2021-05-22 01:11:55 | [online_train] epoch #114 | Time 5632.80 s
2021-05-22 01:11:55 | [online_train] epoch #114 | EpochTime 48.10 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00825906
Average/TrainAverageReturn             203.848
Evaluation/AverageDiscountedReturn     138.497
Evaluation/AverageReturn               216.977
Evaluation/Iteration                   114
Evaluation/MaxReturn                   217.97
Evaluation/MinReturn                   215.042
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.801537
Evaluation/TerminationRate               0
Policy/Loss                           -120.005
QF/Qf1Loss                               0.00355275
QF/Qf2Loss                               0.00469948
ReplayBuffer/buffer_size            460000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.129827
ShortRL/RewardScale                      1.01439
ShortRL/StdHeuristic                     0
TotalEnvSteps                       460000
----------------------------------  ---------------
2021-05-22 01:12:44 | [online_train] epoch #115 | Saving snapshot...
2021-05-22 01:12:44 | [online_train] epoch #115 | Saved
2021-05-22 01:12:44 | [online_train] epoch #115 | Time 5681.15 s
2021-05-22 01:12:44 | [online_train] epoch #115 | EpochTime 48.35 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00820823
Average/TrainAverageReturn             203.533
Evaluation/AverageDiscountedReturn     138.344
Evaluation/AverageReturn               216.844
Evaluation/Iteration                   115
Evaluation/MaxReturn                   217.791
Evaluation/MinReturn                   215.92
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.587534
Evaluation/TerminationRate               0
Policy/Loss                           -121.706
QF/Qf1Loss                               0.00641711
QF/Qf2Loss                               0.00388391
ReplayBuffer/buffer_size            464000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.130603
ShortRL/RewardScale                      1.01639
ShortRL/StdHeuristic                     0
TotalEnvSteps                       464000
----------------------------------  ---------------
2021-05-22 01:13:32 | [online_train] epoch #116 | Saving snapshot...
2021-05-22 01:13:32 | [online_train] epoch #116 | Saved
2021-05-22 01:13:32 | [online_train] epoch #116 | Time 5729.23 s
2021-05-22 01:13:32 | [online_train] epoch #116 | EpochTime 48.07 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00882756
Average/TrainAverageReturn             203.464
Evaluation/AverageDiscountedReturn     142.766
Evaluation/AverageReturn               222.494
Evaluation/Iteration                   116
Evaluation/MaxReturn                   230.151
Evaluation/MinReturn                   216.099
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.81285
Evaluation/TerminationRate               0
Policy/Loss                           -122.821
QF/Qf1Loss                               0.00421441
QF/Qf2Loss                               0.00500741
ReplayBuffer/buffer_size            468000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.131374
ShortRL/RewardScale                      1.01903
ShortRL/StdHeuristic                     0
TotalEnvSteps                       468000
----------------------------------  ---------------
2021-05-22 01:14:27 | [online_train] epoch #117 | Saving snapshot...
2021-05-22 01:14:27 | [online_train] epoch #117 | Saved
2021-05-22 01:14:27 | [online_train] epoch #117 | Time 5784.58 s
2021-05-22 01:14:27 | [online_train] epoch #117 | EpochTime 55.34 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00848821
Average/TrainAverageReturn             204.341
Evaluation/AverageDiscountedReturn     142.425
Evaluation/AverageReturn               222.971
Evaluation/Iteration                   117
Evaluation/MaxReturn                   224.354
Evaluation/MinReturn                   219.116
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.41894
Evaluation/TerminationRate               0
Policy/Loss                           -122.601
QF/Qf1Loss                               0.00234394
QF/Qf2Loss                               0.00365864
ReplayBuffer/buffer_size            472000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.13233
ShortRL/RewardScale                      1.02284
ShortRL/StdHeuristic                     0
TotalEnvSteps                       472000
----------------------------------  ---------------
2021-05-22 01:15:16 | [online_train] epoch #118 | Saving snapshot...
2021-05-22 01:15:16 | [online_train] epoch #118 | Saved
2021-05-22 01:15:16 | [online_train] epoch #118 | Time 5833.48 s
2021-05-22 01:15:16 | [online_train] epoch #118 | EpochTime 48.90 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00851963
Average/TrainAverageReturn             204.529
Evaluation/AverageDiscountedReturn     142.313
Evaluation/AverageReturn               223.098
Evaluation/Iteration                   118
Evaluation/MaxReturn                   224.046
Evaluation/MinReturn                   222.209
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.587244
Evaluation/TerminationRate               0
Policy/Loss                           -124.816
QF/Qf1Loss                               0.00330741
QF/Qf2Loss                               0.0040688
ReplayBuffer/buffer_size            476000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.133093
ShortRL/RewardScale                      1.02566
ShortRL/StdHeuristic                     0
TotalEnvSteps                       476000
----------------------------------  ---------------
2021-05-22 01:16:03 | [online_train] epoch #119 | Saving snapshot...
2021-05-22 01:16:03 | [online_train] epoch #119 | Saved
2021-05-22 01:16:03 | [online_train] epoch #119 | Time 5880.39 s
2021-05-22 01:16:03 | [online_train] epoch #119 | EpochTime 46.91 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00827663
Average/TrainAverageReturn             204.753
Evaluation/AverageDiscountedReturn     138.602
Evaluation/AverageReturn               214.333
Evaluation/Iteration                   119
Evaluation/MaxReturn                   221.682
Evaluation/MinReturn                   200.753
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     6.19686
Evaluation/TerminationRate               0
Policy/Loss                           -126.073
QF/Qf1Loss                               0.006436
QF/Qf2Loss                               0.00394014
ReplayBuffer/buffer_size            480000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.133817
ShortRL/RewardScale                      1.0284
ShortRL/StdHeuristic                     0
TotalEnvSteps                       480000
----------------------------------  ---------------
2021-05-22 01:16:50 | [online_train] epoch #120 | Saving snapshot...
2021-05-22 01:16:50 | [online_train] epoch #120 | Saved
2021-05-22 01:16:50 | [online_train] epoch #120 | Time 5927.89 s
2021-05-22 01:16:50 | [online_train] epoch #120 | EpochTime 47.49 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0084386
Average/TrainAverageReturn             205.103
Evaluation/AverageDiscountedReturn     136.344
Evaluation/AverageReturn               205.105
Evaluation/Iteration                   120
Evaluation/MaxReturn                   209.998
Evaluation/MinReturn                   199.389
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.41344
Evaluation/TerminationRate               0
Policy/Loss                           -124.223
QF/Qf1Loss                               0.00686216
QF/Qf2Loss                               0.00644144
ReplayBuffer/buffer_size            484000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.134538
ShortRL/RewardScale                      1.0307
ShortRL/StdHeuristic                     0
TotalEnvSteps                       484000
----------------------------------  ---------------
2021-05-22 01:17:37 | [online_train] epoch #121 | Saving snapshot...
2021-05-22 01:17:37 | [online_train] epoch #121 | Saved
2021-05-22 01:17:37 | [online_train] epoch #121 | Time 5974.77 s
2021-05-22 01:17:37 | [online_train] epoch #121 | EpochTime 46.88 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00818081
Average/TrainAverageReturn             204.925
Evaluation/AverageDiscountedReturn     145.524
Evaluation/AverageReturn               228.547
Evaluation/Iteration                   121
Evaluation/MaxReturn                   229.491
Evaluation/MinReturn                   227.789
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.607822
Evaluation/TerminationRate               0
Policy/Loss                           -124.271
QF/Qf1Loss                               0.00638617
QF/Qf2Loss                               0.00436221
ReplayBuffer/buffer_size            488000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.135267
ShortRL/RewardScale                      1.03313
ShortRL/StdHeuristic                     0
TotalEnvSteps                       488000
----------------------------------  ---------------
2021-05-22 01:18:24 | [online_train] epoch #122 | Saving snapshot...
2021-05-22 01:18:24 | [online_train] epoch #122 | Saved
2021-05-22 01:18:24 | [online_train] epoch #122 | Time 6022.06 s
2021-05-22 01:18:24 | [online_train] epoch #122 | EpochTime 47.29 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00791311
Average/TrainAverageReturn             205.224
Evaluation/AverageDiscountedReturn     146.265
Evaluation/AverageReturn               229.893
Evaluation/Iteration                   122
Evaluation/MaxReturn                   230.924
Evaluation/MinReturn                   229.176
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.583687
Evaluation/TerminationRate               0
Policy/Loss                           -127.284
QF/Qf1Loss                               0.00411241
QF/Qf2Loss                               0.00443333
ReplayBuffer/buffer_size            492000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.136013
ShortRL/RewardScale                      1.03615
ShortRL/StdHeuristic                     0
TotalEnvSteps                       492000
----------------------------------  ---------------
2021-05-22 01:19:12 | [online_train] epoch #123 | Saving snapshot...
2021-05-22 01:19:12 | [online_train] epoch #123 | Saved
2021-05-22 01:19:12 | [online_train] epoch #123 | Time 6069.56 s
2021-05-22 01:19:12 | [online_train] epoch #123 | EpochTime 47.49 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00813178
Average/TrainAverageReturn             205.447
Evaluation/AverageDiscountedReturn     147.012
Evaluation/AverageReturn               231.125
Evaluation/Iteration                   123
Evaluation/MaxReturn                   232.753
Evaluation/MinReturn                   227.671
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.29546
Evaluation/TerminationRate               0
Policy/Loss                           -125.992
QF/Qf1Loss                               0.00203603
QF/Qf2Loss                               0.0043624
ReplayBuffer/buffer_size            496000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.13683
ShortRL/RewardScale                      1.03918
ShortRL/StdHeuristic                     0
TotalEnvSteps                       496000
----------------------------------  ---------------
2021-05-22 01:19:59 | [online_train] epoch #124 | Saving snapshot...
2021-05-22 01:19:59 | [online_train] epoch #124 | Saved
2021-05-22 01:19:59 | [online_train] epoch #124 | Time 6116.53 s
2021-05-22 01:19:59 | [online_train] epoch #124 | EpochTime 46.96 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00795611
Average/TrainAverageReturn             206.041
Evaluation/AverageDiscountedReturn     141.795
Evaluation/AverageReturn               222.073
Evaluation/Iteration                   124
Evaluation/MaxReturn                   222.935
Evaluation/MinReturn                   220.666
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.765754
Evaluation/TerminationRate               0
Policy/Loss                           -129.424
QF/Qf1Loss                               0.00304263
QF/Qf2Loss                               0.00475472
ReplayBuffer/buffer_size            500000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.137722
ShortRL/RewardScale                      1.04185
ShortRL/StdHeuristic                     0
TotalEnvSteps                       500000
----------------------------------  ---------------
2021-05-22 01:20:46 | [online_train] epoch #125 | Saving snapshot...
2021-05-22 01:20:47 | [online_train] epoch #125 | Saved
2021-05-22 01:20:47 | [online_train] epoch #125 | Time 6164.10 s
2021-05-22 01:20:47 | [online_train] epoch #125 | EpochTime 47.57 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0082603
Average/TrainAverageReturn             206.198
Evaluation/AverageDiscountedReturn     143.975
Evaluation/AverageReturn               223.706
Evaluation/Iteration                   125
Evaluation/MaxReturn                   231.21
Evaluation/MinReturn                   216.656
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     5.80346
Evaluation/TerminationRate               0
Policy/Loss                           -129.002
QF/Qf1Loss                               0.00716748
QF/Qf2Loss                               0.0105445
ReplayBuffer/buffer_size            504000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.13851
ShortRL/RewardScale                      1.0441
ShortRL/StdHeuristic                     0
TotalEnvSteps                       504000
----------------------------------  ---------------
2021-05-22 01:21:34 | [online_train] epoch #126 | Saving snapshot...
2021-05-22 01:21:34 | [online_train] epoch #126 | Saved
2021-05-22 01:21:34 | [online_train] epoch #126 | Time 6211.41 s
2021-05-22 01:21:34 | [online_train] epoch #126 | EpochTime 47.30 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00780108
Average/TrainAverageReturn             206.771
Evaluation/AverageDiscountedReturn     141.816
Evaluation/AverageReturn               215.222
Evaluation/Iteration                   126
Evaluation/MaxReturn                   221.2
Evaluation/MinReturn                   210.521
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.29757
Evaluation/TerminationRate               0
Policy/Loss                           -128.676
QF/Qf1Loss                               0.00698145
QF/Qf2Loss                               0.00627645
ReplayBuffer/buffer_size            508000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.139243
ShortRL/RewardScale                      1.04655
ShortRL/StdHeuristic                     0
TotalEnvSteps                       508000
----------------------------------  ---------------
2021-05-22 01:22:21 | [online_train] epoch #127 | Saving snapshot...
2021-05-22 01:22:21 | [online_train] epoch #127 | Saved
2021-05-22 01:22:21 | [online_train] epoch #127 | Time 6258.40 s
2021-05-22 01:22:21 | [online_train] epoch #127 | EpochTime 46.98 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00818003
Average/TrainAverageReturn             207.673
Evaluation/AverageDiscountedReturn     144.378
Evaluation/AverageReturn               224.203
Evaluation/Iteration                   127
Evaluation/MaxReturn                   230.165
Evaluation/MinReturn                   213.733
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     6.05345
Evaluation/TerminationRate               0
Policy/Loss                           -129.813
QF/Qf1Loss                               0.00826292
QF/Qf2Loss                               0.0103347
ReplayBuffer/buffer_size            512000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.140084
ShortRL/RewardScale                      1.04946
ShortRL/StdHeuristic                     0
TotalEnvSteps                       512000
----------------------------------  ---------------
2021-05-22 01:23:08 | [online_train] epoch #128 | Saving snapshot...
2021-05-22 01:23:08 | [online_train] epoch #128 | Saved
2021-05-22 01:23:08 | [online_train] epoch #128 | Time 6305.89 s
2021-05-22 01:23:08 | [online_train] epoch #128 | EpochTime 47.49 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00771617
Average/TrainAverageReturn             208.312
Evaluation/AverageDiscountedReturn     140.02
Evaluation/AverageReturn               213.857
Evaluation/Iteration                   128
Evaluation/MaxReturn                   224.732
Evaluation/MinReturn                   203.002
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     6.46138
Evaluation/TerminationRate               0
Policy/Loss                           -129.71
QF/Qf1Loss                               0.0086738
QF/Qf2Loss                               0.00402733
ReplayBuffer/buffer_size            516000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.140908
ShortRL/RewardScale                      1.05199
ShortRL/StdHeuristic                     0
TotalEnvSteps                       516000
----------------------------------  ---------------
2021-05-22 01:23:56 | [online_train] epoch #129 | Saving snapshot...
2021-05-22 01:23:56 | [online_train] epoch #129 | Saved
2021-05-22 01:23:56 | [online_train] epoch #129 | Time 6353.12 s
2021-05-22 01:23:56 | [online_train] epoch #129 | EpochTime 47.22 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0080534
Average/TrainAverageReturn             208.456
Evaluation/AverageDiscountedReturn     142.242
Evaluation/AverageReturn               221.783
Evaluation/Iteration                   129
Evaluation/MaxReturn                   226.334
Evaluation/MinReturn                   214.111
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.30344
Evaluation/TerminationRate               0
Policy/Loss                           -130.064
QF/Qf1Loss                               0.00713223
QF/Qf2Loss                               0.00599721
ReplayBuffer/buffer_size            520000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.141582
ShortRL/RewardScale                      1.05525
ShortRL/StdHeuristic                     0
TotalEnvSteps                       520000
----------------------------------  ---------------
2021-05-22 01:24:43 | [online_train] epoch #130 | Saving snapshot...
2021-05-22 01:24:43 | [online_train] epoch #130 | Saved
2021-05-22 01:24:43 | [online_train] epoch #130 | Time 6400.36 s
2021-05-22 01:24:43 | [online_train] epoch #130 | EpochTime 47.23 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00773274
Average/TrainAverageReturn             208.693
Evaluation/AverageDiscountedReturn     145.332
Evaluation/AverageReturn               227.303
Evaluation/Iteration                   130
Evaluation/MaxReturn                   230.381
Evaluation/MinReturn                   220.88
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.2887
Evaluation/TerminationRate               0
Policy/Loss                           -132.265
QF/Qf1Loss                               0.0026181
QF/Qf2Loss                               0.00308022
ReplayBuffer/buffer_size            524000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.142226
ShortRL/RewardScale                      1.05684
ShortRL/StdHeuristic                     0
TotalEnvSteps                       524000
----------------------------------  ---------------
2021-05-22 01:25:30 | [online_train] epoch #131 | Saving snapshot...
2021-05-22 01:25:30 | [online_train] epoch #131 | Saved
2021-05-22 01:25:30 | [online_train] epoch #131 | Time 6447.97 s
2021-05-22 01:25:30 | [online_train] epoch #131 | EpochTime 47.60 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00807174
Average/TrainAverageReturn             208.76
Evaluation/AverageDiscountedReturn     144.29
Evaluation/AverageReturn               226.292
Evaluation/Iteration                   131
Evaluation/MaxReturn                   227.517
Evaluation/MinReturn                   225.172
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.601321
Evaluation/TerminationRate               0
Policy/Loss                           -129.996
QF/Qf1Loss                               0.00418063
QF/Qf2Loss                               0.00599616
ReplayBuffer/buffer_size            528000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.142862
ShortRL/RewardScale                      1.05928
ShortRL/StdHeuristic                     0
TotalEnvSteps                       528000
----------------------------------  ---------------
2021-05-22 01:26:18 | [online_train] epoch #132 | Saving snapshot...
2021-05-22 01:26:18 | [online_train] epoch #132 | Saved
2021-05-22 01:26:18 | [online_train] epoch #132 | Time 6495.79 s
2021-05-22 01:26:18 | [online_train] epoch #132 | EpochTime 47.81 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00766084
Average/TrainAverageReturn             209.376
Evaluation/AverageDiscountedReturn     134.019
Evaluation/AverageReturn               200.954
Evaluation/Iteration                   132
Evaluation/MaxReturn                   209.484
Evaluation/MinReturn                   197.733
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.06446
Evaluation/TerminationRate               0
Policy/Loss                           -130.891
QF/Qf1Loss                               0.00429789
QF/Qf2Loss                               0.00456526
ReplayBuffer/buffer_size            532000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.143605
ShortRL/RewardScale                      1.06122
ShortRL/StdHeuristic                     0
TotalEnvSteps                       532000
----------------------------------  ---------------
2021-05-22 01:27:06 | [online_train] epoch #133 | Saving snapshot...
2021-05-22 01:27:06 | [online_train] epoch #133 | Saved
2021-05-22 01:27:06 | [online_train] epoch #133 | Time 6543.27 s
2021-05-22 01:27:06 | [online_train] epoch #133 | EpochTime 47.47 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00788638
Average/TrainAverageReturn             209.494
Evaluation/AverageDiscountedReturn     145.096
Evaluation/AverageReturn               228.357
Evaluation/Iteration                   133
Evaluation/MaxReturn                   229.547
Evaluation/MinReturn                   227.471
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.664062
Evaluation/TerminationRate               0
Policy/Loss                           -132.795
QF/Qf1Loss                               0.00807827
QF/Qf2Loss                               0.00803905
ReplayBuffer/buffer_size            536000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.144152
ShortRL/RewardScale                      1.06287
ShortRL/StdHeuristic                     0
TotalEnvSteps                       536000
----------------------------------  ---------------
2021-05-22 01:27:53 | [online_train] epoch #134 | Saving snapshot...
2021-05-22 01:27:53 | [online_train] epoch #134 | Saved
2021-05-22 01:27:53 | [online_train] epoch #134 | Time 6590.60 s
2021-05-22 01:27:53 | [online_train] epoch #134 | EpochTime 47.33 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00799007
Average/TrainAverageReturn             209.623
Evaluation/AverageDiscountedReturn     138.705
Evaluation/AverageReturn               210.609
Evaluation/Iteration                   134
Evaluation/MaxReturn                   216.764
Evaluation/MinReturn                   204.319
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.52265
Evaluation/TerminationRate               0
Policy/Loss                           -134.605
QF/Qf1Loss                               0.00275183
QF/Qf2Loss                               0.00323272
ReplayBuffer/buffer_size            540000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.144788
ShortRL/RewardScale                      1.0657
ShortRL/StdHeuristic                     0
TotalEnvSteps                       540000
----------------------------------  ---------------
2021-05-22 01:28:40 | [online_train] epoch #135 | Saving snapshot...
2021-05-22 01:28:40 | [online_train] epoch #135 | Saved
2021-05-22 01:28:40 | [online_train] epoch #135 | Time 6638.01 s
2021-05-22 01:28:40 | [online_train] epoch #135 | EpochTime 47.41 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00787123
Average/TrainAverageReturn             209.577
Evaluation/AverageDiscountedReturn     135.787
Evaluation/AverageReturn               204.193
Evaluation/Iteration                   135
Evaluation/MaxReturn                   208.312
Evaluation/MinReturn                   199.845
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.14958
Evaluation/TerminationRate               0
Policy/Loss                           -133.626
QF/Qf1Loss                               0.00936734
QF/Qf2Loss                               0.00698268
ReplayBuffer/buffer_size            544000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.145466
ShortRL/RewardScale                      1.06714
ShortRL/StdHeuristic                     0
TotalEnvSteps                       544000
----------------------------------  ---------------
2021-05-22 01:29:28 | [online_train] epoch #136 | Saving snapshot...
2021-05-22 01:29:28 | [online_train] epoch #136 | Saved
2021-05-22 01:29:28 | [online_train] epoch #136 | Time 6685.14 s
2021-05-22 01:29:28 | [online_train] epoch #136 | EpochTime 47.12 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00756558
Average/TrainAverageReturn             210.026
Evaluation/AverageDiscountedReturn     143.934
Evaluation/AverageReturn               225.871
Evaluation/Iteration                   136
Evaluation/MaxReturn                   228.407
Evaluation/MinReturn                   221.608
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.0324
Evaluation/TerminationRate               0
Policy/Loss                           -132.901
QF/Qf1Loss                               0.00345066
QF/Qf2Loss                               0.0040737
ReplayBuffer/buffer_size            548000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.146189
ShortRL/RewardScale                      1.06927
ShortRL/StdHeuristic                     0
TotalEnvSteps                       548000
----------------------------------  ---------------
2021-05-22 01:30:15 | [online_train] epoch #137 | Saving snapshot...
2021-05-22 01:30:15 | [online_train] epoch #137 | Saved
2021-05-22 01:30:15 | [online_train] epoch #137 | Time 6732.20 s
2021-05-22 01:30:15 | [online_train] epoch #137 | EpochTime 47.06 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00767917
Average/TrainAverageReturn             210.005
Evaluation/AverageDiscountedReturn     144.538
Evaluation/AverageReturn               227.21
Evaluation/Iteration                   137
Evaluation/MaxReturn                   229.44
Evaluation/MinReturn                   220.857
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.36916
Evaluation/TerminationRate               0
Policy/Loss                           -134.567
QF/Qf1Loss                               0.00296737
QF/Qf2Loss                               0.00406139
ReplayBuffer/buffer_size            552000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.146766
ShortRL/RewardScale                      1.072
ShortRL/StdHeuristic                     0
TotalEnvSteps                       552000
----------------------------------  ---------------
2021-05-22 01:31:02 | [online_train] epoch #138 | Saving snapshot...
2021-05-22 01:31:02 | [online_train] epoch #138 | Saved
2021-05-22 01:31:02 | [online_train] epoch #138 | Time 6779.77 s
2021-05-22 01:31:02 | [online_train] epoch #138 | EpochTime 47.56 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00765004
Average/TrainAverageReturn             210.688
Evaluation/AverageDiscountedReturn     145.452
Evaluation/AverageReturn               227.274
Evaluation/Iteration                   138
Evaluation/MaxReturn                   231.37
Evaluation/MinReturn                   222.938
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.2886
Evaluation/TerminationRate               0
Policy/Loss                           -135.524
QF/Qf1Loss                               0.00907204
QF/Qf2Loss                               0.00588372
ReplayBuffer/buffer_size            556000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.147418
ShortRL/RewardScale                      1.0745
ShortRL/StdHeuristic                     0
TotalEnvSteps                       556000
----------------------------------  ---------------
2021-05-22 01:31:50 | [online_train] epoch #139 | Saving snapshot...
2021-05-22 01:31:50 | [online_train] epoch #139 | Saved
2021-05-22 01:31:50 | [online_train] epoch #139 | Time 6827.17 s
2021-05-22 01:31:50 | [online_train] epoch #139 | EpochTime 47.40 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00769953
Average/TrainAverageReturn             211.159
Evaluation/AverageDiscountedReturn     142.733
Evaluation/AverageReturn               221.345
Evaluation/Iteration                   139
Evaluation/MaxReturn                   228.058
Evaluation/MinReturn                   210.754
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     5.78977
Evaluation/TerminationRate               0
Policy/Loss                           -136.683
QF/Qf1Loss                               0.00260158
QF/Qf2Loss                               0.00229329
ReplayBuffer/buffer_size            560000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.148057
ShortRL/RewardScale                      1.07657
ShortRL/StdHeuristic                     0
TotalEnvSteps                       560000
----------------------------------  ---------------
2021-05-22 01:32:37 | [online_train] epoch #140 | Saving snapshot...
2021-05-22 01:32:37 | [online_train] epoch #140 | Saved
2021-05-22 01:32:37 | [online_train] epoch #140 | Time 6874.14 s
2021-05-22 01:32:37 | [online_train] epoch #140 | EpochTime 46.96 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00792097
Average/TrainAverageReturn             211.682
Evaluation/AverageDiscountedReturn     145.188
Evaluation/AverageReturn               228.979
Evaluation/Iteration                   140
Evaluation/MaxReturn                   230.471
Evaluation/MinReturn                   226.701
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.14442
Evaluation/TerminationRate               0
Policy/Loss                           -136.369
QF/Qf1Loss                               0.0067331
QF/Qf2Loss                               0.00527214
ReplayBuffer/buffer_size            564000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.148741
ShortRL/RewardScale                      1.07855
ShortRL/StdHeuristic                     0
TotalEnvSteps                       564000
----------------------------------  ---------------
2021-05-22 01:33:22 | [online_train] epoch #141 | Saving snapshot...
2021-05-22 01:33:22 | [online_train] epoch #141 | Saved
2021-05-22 01:33:22 | [online_train] epoch #141 | Time 6919.99 s
2021-05-22 01:33:22 | [online_train] epoch #141 | EpochTime 45.85 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00761434
Average/TrainAverageReturn             211.65
Evaluation/AverageDiscountedReturn     135.947
Evaluation/AverageReturn               203.522
Evaluation/Iteration                   141
Evaluation/MaxReturn                   205.378
Evaluation/MinReturn                   201.919
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.14069
Evaluation/TerminationRate               0
Policy/Loss                           -136.634
QF/Qf1Loss                               0.0074007
QF/Qf2Loss                               0.00374785
ReplayBuffer/buffer_size            568000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.149225
ShortRL/RewardScale                      1.08128
ShortRL/StdHeuristic                     0
TotalEnvSteps                       568000
----------------------------------  ---------------
2021-05-22 01:34:09 | [online_train] epoch #142 | Saving snapshot...
2021-05-22 01:34:09 | [online_train] epoch #142 | Saved
2021-05-22 01:34:09 | [online_train] epoch #142 | Time 6966.40 s
2021-05-22 01:34:09 | [online_train] epoch #142 | EpochTime 46.40 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00741505
Average/TrainAverageReturn             211.843
Evaluation/AverageDiscountedReturn     145.039
Evaluation/AverageReturn               225.707
Evaluation/Iteration                   142
Evaluation/MaxReturn                   232.79
Evaluation/MinReturn                   218.522
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     4.82351
Evaluation/TerminationRate               0
Policy/Loss                           -138.4
QF/Qf1Loss                               0.00315956
QF/Qf2Loss                               0.00290259
ReplayBuffer/buffer_size            572000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.149882
ShortRL/RewardScale                      1.08397
ShortRL/StdHeuristic                     0
TotalEnvSteps                       572000
----------------------------------  ---------------
2021-05-22 01:34:56 | [online_train] epoch #143 | Saving snapshot...
2021-05-22 01:34:56 | [online_train] epoch #143 | Saved
2021-05-22 01:34:56 | [online_train] epoch #143 | Time 7013.15 s
2021-05-22 01:34:56 | [online_train] epoch #143 | EpochTime 46.74 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00766032
Average/TrainAverageReturn             211.889
Evaluation/AverageDiscountedReturn     144.248
Evaluation/AverageReturn               224.89
Evaluation/Iteration                   143
Evaluation/MaxReturn                   228.587
Evaluation/MinReturn                   219.516
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.88035
Evaluation/TerminationRate               0
Policy/Loss                           -138.274
QF/Qf1Loss                               0.00510442
QF/Qf2Loss                               0.0159041
ReplayBuffer/buffer_size            576000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.150462
ShortRL/RewardScale                      1.08636
ShortRL/StdHeuristic                     0
TotalEnvSteps                       576000
----------------------------------  ---------------
2021-05-22 01:35:42 | [online_train] epoch #144 | Saving snapshot...
2021-05-22 01:35:42 | [online_train] epoch #144 | Saved
2021-05-22 01:35:42 | [online_train] epoch #144 | Time 7059.91 s
2021-05-22 01:35:42 | [online_train] epoch #144 | EpochTime 46.76 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00740238
Average/TrainAverageReturn             211.859
Evaluation/AverageDiscountedReturn     141.622
Evaluation/AverageReturn               220.175
Evaluation/Iteration                   144
Evaluation/MaxReturn                   226.151
Evaluation/MinReturn                   213.751
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     4.26073
Evaluation/TerminationRate               0
Policy/Loss                           -139.408
QF/Qf1Loss                               0.00343153
QF/Qf2Loss                               0.00533264
ReplayBuffer/buffer_size            580000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.15092
ShortRL/RewardScale                      1.08876
ShortRL/StdHeuristic                     0
TotalEnvSteps                       580000
----------------------------------  ---------------
2021-05-22 01:36:29 | [online_train] epoch #145 | Saving snapshot...
2021-05-22 01:36:29 | [online_train] epoch #145 | Saved
2021-05-22 01:36:29 | [online_train] epoch #145 | Time 7106.25 s
2021-05-22 01:36:29 | [online_train] epoch #145 | EpochTime 46.33 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0075377
Average/TrainAverageReturn             211.838
Evaluation/AverageDiscountedReturn     141.644
Evaluation/AverageReturn               218.33
Evaluation/Iteration                   145
Evaluation/MaxReturn                   228.384
Evaluation/MinReturn                   211.146
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     5.36305
Evaluation/TerminationRate               0
Policy/Loss                           -138.906
QF/Qf1Loss                               0.00395466
QF/Qf2Loss                               0.00645424
ReplayBuffer/buffer_size            584000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.151376
ShortRL/RewardScale                      1.0912
ShortRL/StdHeuristic                     0
TotalEnvSteps                       584000
----------------------------------  ---------------
2021-05-22 01:37:15 | [online_train] epoch #146 | Saving snapshot...
2021-05-22 01:37:15 | [online_train] epoch #146 | Saved
2021-05-22 01:37:15 | [online_train] epoch #146 | Time 7152.56 s
2021-05-22 01:37:15 | [online_train] epoch #146 | EpochTime 46.30 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00754253
Average/TrainAverageReturn             211.922
Evaluation/AverageDiscountedReturn     148.222
Evaluation/AverageReturn               232.901
Evaluation/Iteration                   146
Evaluation/MaxReturn                   234.352
Evaluation/MinReturn                   229.787
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.43171
Evaluation/TerminationRate               0
Policy/Loss                           -139.626
QF/Qf1Loss                               0.00642831
QF/Qf2Loss                               0.00396633
ReplayBuffer/buffer_size            588000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.15186
ShortRL/RewardScale                      1.09372
ShortRL/StdHeuristic                     0
TotalEnvSteps                       588000
----------------------------------  ---------------
2021-05-22 01:38:01 | [online_train] epoch #147 | Saving snapshot...
2021-05-22 01:38:01 | [online_train] epoch #147 | Saved
2021-05-22 01:38:01 | [online_train] epoch #147 | Time 7198.55 s
2021-05-22 01:38:01 | [online_train] epoch #147 | EpochTime 45.99 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00731473
Average/TrainAverageReturn             211.852
Evaluation/AverageDiscountedReturn     147.57
Evaluation/AverageReturn               231.802
Evaluation/Iteration                   147
Evaluation/MaxReturn                   234.295
Evaluation/MinReturn                   229.297
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.73034
Evaluation/TerminationRate               0
Policy/Loss                           -141.683
QF/Qf1Loss                               0.00777657
QF/Qf2Loss                               0.00789667
ReplayBuffer/buffer_size            592000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.152463
ShortRL/RewardScale                      1.09574
ShortRL/StdHeuristic                     0
TotalEnvSteps                       592000
----------------------------------  ---------------
2021-05-22 01:38:48 | [online_train] epoch #148 | Saving snapshot...
2021-05-22 01:38:48 | [online_train] epoch #148 | Saved
2021-05-22 01:38:48 | [online_train] epoch #148 | Time 7245.23 s
2021-05-22 01:38:48 | [online_train] epoch #148 | EpochTime 46.67 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00739393
Average/TrainAverageReturn             212.362
Evaluation/AverageDiscountedReturn     144.392
Evaluation/AverageReturn               221.772
Evaluation/Iteration                   148
Evaluation/MaxReturn                   228.684
Evaluation/MinReturn                   211.456
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     4.87803
Evaluation/TerminationRate               0
Policy/Loss                           -141.075
QF/Qf1Loss                               0.0058021
QF/Qf2Loss                               0.00648303
ReplayBuffer/buffer_size            596000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.153064
ShortRL/RewardScale                      1.0982
ShortRL/StdHeuristic                     0
TotalEnvSteps                       596000
----------------------------------  ---------------
2021-05-22 01:39:34 | [online_train] epoch #149 | Saving snapshot...
2021-05-22 01:39:34 | [online_train] epoch #149 | Saved
2021-05-22 01:39:34 | [online_train] epoch #149 | Time 7291.44 s
2021-05-22 01:39:34 | [online_train] epoch #149 | EpochTime 46.20 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00762652
Average/TrainAverageReturn             212.839
Evaluation/AverageDiscountedReturn     141.007
Evaluation/AverageReturn               217.251
Evaluation/Iteration                   149
Evaluation/MaxReturn                   221.302
Evaluation/MinReturn                   213.604
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.60246
Evaluation/TerminationRate               0
Policy/Loss                           -140.855
QF/Qf1Loss                               0.00411904
QF/Qf2Loss                               0.00408259
ReplayBuffer/buffer_size            600000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.153625
ShortRL/RewardScale                      1.101
ShortRL/StdHeuristic                     0
TotalEnvSteps                       600000
----------------------------------  ---------------
2021-05-22 01:40:21 | [online_train] epoch #150 | Saving snapshot...
2021-05-22 01:40:21 | [online_train] epoch #150 | Saved
2021-05-22 01:40:21 | [online_train] epoch #150 | Time 7338.13 s
2021-05-22 01:40:21 | [online_train] epoch #150 | EpochTime 46.68 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00745137
Average/TrainAverageReturn             212.954
Evaluation/AverageDiscountedReturn     145.153
Evaluation/AverageReturn               225.672
Evaluation/Iteration                   150
Evaluation/MaxReturn                   231.527
Evaluation/MinReturn                   217.249
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.55751
Evaluation/TerminationRate               0
Policy/Loss                           -142.22
QF/Qf1Loss                               0.00550609
QF/Qf2Loss                               0.00520443
ReplayBuffer/buffer_size            604000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.154092
ShortRL/RewardScale                      1.10274
ShortRL/StdHeuristic                     0
TotalEnvSteps                       604000
----------------------------------  ---------------
2021-05-22 01:41:07 | [online_train] epoch #151 | Saving snapshot...
2021-05-22 01:41:07 | [online_train] epoch #151 | Saved
2021-05-22 01:41:07 | [online_train] epoch #151 | Time 7384.63 s
2021-05-22 01:41:07 | [online_train] epoch #151 | EpochTime 46.50 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00728151
Average/TrainAverageReturn             212.876
Evaluation/AverageDiscountedReturn     147.186
Evaluation/AverageReturn               231.395
Evaluation/Iteration                   151
Evaluation/MaxReturn                   233.806
Evaluation/MinReturn                   227.293
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.04312
Evaluation/TerminationRate               0
Policy/Loss                           -143.059
QF/Qf1Loss                               0.00275855
QF/Qf2Loss                               0.00305028
ReplayBuffer/buffer_size            608000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.154517
ShortRL/RewardScale                      1.10503
ShortRL/StdHeuristic                     0
TotalEnvSteps                       608000
----------------------------------  ---------------
2021-05-22 01:41:54 | [online_train] epoch #152 | Saving snapshot...
2021-05-22 01:41:54 | [online_train] epoch #152 | Saved
2021-05-22 01:41:54 | [online_train] epoch #152 | Time 7431.51 s
2021-05-22 01:41:54 | [online_train] epoch #152 | EpochTime 46.87 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00755695
Average/TrainAverageReturn             213.335
Evaluation/AverageDiscountedReturn     149.03
Evaluation/AverageReturn               233.688
Evaluation/Iteration                   152
Evaluation/MaxReturn                   235.114
Evaluation/MinReturn                   232.182
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.837544
Evaluation/TerminationRate               0
Policy/Loss                           -144.693
QF/Qf1Loss                               0.0084847
QF/Qf2Loss                               0.0065551
ReplayBuffer/buffer_size            612000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.155104
ShortRL/RewardScale                      1.10682
ShortRL/StdHeuristic                     0
TotalEnvSteps                       612000
----------------------------------  ---------------
2021-05-22 01:42:40 | [online_train] epoch #153 | Saving snapshot...
2021-05-22 01:42:41 | [online_train] epoch #153 | Saved
2021-05-22 01:42:41 | [online_train] epoch #153 | Time 7478.10 s
2021-05-22 01:42:41 | [online_train] epoch #153 | EpochTime 46.59 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00773499
Average/TrainAverageReturn             213.607
Evaluation/AverageDiscountedReturn     145.752
Evaluation/AverageReturn               229.801
Evaluation/Iteration                   153
Evaluation/MaxReturn                   231.64
Evaluation/MinReturn                   228.502
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.034
Evaluation/TerminationRate               0
Policy/Loss                           -143.317
QF/Qf1Loss                               0.00302048
QF/Qf2Loss                               0.00448314
ReplayBuffer/buffer_size            616000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.155703
ShortRL/RewardScale                      1.10845
ShortRL/StdHeuristic                     0
TotalEnvSteps                       616000
----------------------------------  ---------------
2021-05-22 01:43:27 | [online_train] epoch #154 | Saving snapshot...
2021-05-22 01:43:27 | [online_train] epoch #154 | Saved
2021-05-22 01:43:27 | [online_train] epoch #154 | Time 7524.20 s
2021-05-22 01:43:27 | [online_train] epoch #154 | EpochTime 46.09 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00710443
Average/TrainAverageReturn             213.456
Evaluation/AverageDiscountedReturn     135.797
Evaluation/AverageReturn               202.831
Evaluation/Iteration                   154
Evaluation/MaxReturn                   204.338
Evaluation/MinReturn                   201.599
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.981966
Evaluation/TerminationRate               0
Policy/Loss                           -144.541
QF/Qf1Loss                               0.0024288
QF/Qf2Loss                               0.00292196
ReplayBuffer/buffer_size            620000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.156261
ShortRL/RewardScale                      1.11026
ShortRL/StdHeuristic                     0
TotalEnvSteps                       620000
----------------------------------  ---------------
2021-05-22 01:44:13 | [online_train] epoch #155 | Saving snapshot...
2021-05-22 01:44:13 | [online_train] epoch #155 | Saved
2021-05-22 01:44:13 | [online_train] epoch #155 | Time 7570.58 s
2021-05-22 01:44:13 | [online_train] epoch #155 | EpochTime 46.38 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00702943
Average/TrainAverageReturn             213.353
Evaluation/AverageDiscountedReturn     150.227
Evaluation/AverageReturn               237.065
Evaluation/Iteration                   155
Evaluation/MaxReturn                   237.758
Evaluation/MinReturn                   236.622
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.308466
Evaluation/TerminationRate               0
Policy/Loss                           -144.396
QF/Qf1Loss                               0.00317112
QF/Qf2Loss                               0.0030392
ReplayBuffer/buffer_size            624000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.156746
ShortRL/RewardScale                      1.11201
ShortRL/StdHeuristic                     0
TotalEnvSteps                       624000
----------------------------------  ---------------
2021-05-22 01:45:06 | [online_train] epoch #156 | Saving snapshot...
2021-05-22 01:45:06 | [online_train] epoch #156 | Saved
2021-05-22 01:45:06 | [online_train] epoch #156 | Time 7623.82 s
2021-05-22 01:45:06 | [online_train] epoch #156 | EpochTime 53.23 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00733085
Average/TrainAverageReturn             213.473
Evaluation/AverageDiscountedReturn     136.134
Evaluation/AverageReturn               203.928
Evaluation/Iteration                   156
Evaluation/MaxReturn                   206.42
Evaluation/MinReturn                   202.334
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.29248
Evaluation/TerminationRate               0
Policy/Loss                           -144.885
QF/Qf1Loss                               0.00513286
QF/Qf2Loss                               0.00317681
ReplayBuffer/buffer_size            628000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.157247
ShortRL/RewardScale                      1.11423
ShortRL/StdHeuristic                     0
TotalEnvSteps                       628000
----------------------------------  ---------------
2021-05-22 01:45:53 | [online_train] epoch #157 | Saving snapshot...
2021-05-22 01:45:53 | [online_train] epoch #157 | Saved
2021-05-22 01:45:53 | [online_train] epoch #157 | Time 7670.63 s
2021-05-22 01:45:53 | [online_train] epoch #157 | EpochTime 46.81 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00772155
Average/TrainAverageReturn             213.274
Evaluation/AverageDiscountedReturn     136.874
Evaluation/AverageReturn               204.584
Evaluation/Iteration                   157
Evaluation/MaxReturn                   206.668
Evaluation/MinReturn                   203.104
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.25589
Evaluation/TerminationRate               0
Policy/Loss                           -143.151
QF/Qf1Loss                               0.00421104
QF/Qf2Loss                               0.00539911
ReplayBuffer/buffer_size            632000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.157762
ShortRL/RewardScale                      1.11604
ShortRL/StdHeuristic                     0
TotalEnvSteps                       632000
----------------------------------  ---------------
2021-05-22 01:46:40 | [online_train] epoch #158 | Saving snapshot...
2021-05-22 01:46:40 | [online_train] epoch #158 | Saved
2021-05-22 01:46:40 | [online_train] epoch #158 | Time 7717.34 s
2021-05-22 01:46:40 | [online_train] epoch #158 | EpochTime 46.71 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00759687
Average/TrainAverageReturn             212.808
Evaluation/AverageDiscountedReturn     135.49
Evaluation/AverageReturn               202.74
Evaluation/Iteration                   158
Evaluation/MaxReturn                   203.682
Evaluation/MinReturn                   202.001
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.585358
Evaluation/TerminationRate               0
Policy/Loss                           -144.369
QF/Qf1Loss                               0.00952281
QF/Qf2Loss                               0.00557343
ReplayBuffer/buffer_size            636000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.158199
ShortRL/RewardScale                      1.11781
ShortRL/StdHeuristic                     0
TotalEnvSteps                       636000
----------------------------------  ---------------
2021-05-22 01:47:26 | [online_train] epoch #159 | Saving snapshot...
2021-05-22 01:47:26 | [online_train] epoch #159 | Saved
2021-05-22 01:47:26 | [online_train] epoch #159 | Time 7763.85 s
2021-05-22 01:47:26 | [online_train] epoch #159 | EpochTime 46.50 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00748883
Average/TrainAverageReturn             213.216
Evaluation/AverageDiscountedReturn     143.166
Evaluation/AverageReturn               226.426
Evaluation/Iteration                   159
Evaluation/MaxReturn                   226.997
Evaluation/MinReturn                   225.932
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.336028
Evaluation/TerminationRate               0
Policy/Loss                           -145.75
QF/Qf1Loss                               0.00675785
QF/Qf2Loss                               0.00578491
ReplayBuffer/buffer_size            640000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.158735
ShortRL/RewardScale                      1.12026
ShortRL/StdHeuristic                     0
TotalEnvSteps                       640000
----------------------------------  ---------------
2021-05-22 01:48:13 | [online_train] epoch #160 | Saving snapshot...
2021-05-22 01:48:13 | [online_train] epoch #160 | Saved
2021-05-22 01:48:13 | [online_train] epoch #160 | Time 7810.77 s
2021-05-22 01:48:13 | [online_train] epoch #160 | EpochTime 46.91 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00757049
Average/TrainAverageReturn             213.58
Evaluation/AverageDiscountedReturn     138.424
Evaluation/AverageReturn               208.626
Evaluation/Iteration                   160
Evaluation/MaxReturn                   213.305
Evaluation/MinReturn                   207.192
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.68646
Evaluation/TerminationRate               0
Policy/Loss                           -146.827
QF/Qf1Loss                               0.00539446
QF/Qf2Loss                               0.00448708
ReplayBuffer/buffer_size            644000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.159236
ShortRL/RewardScale                      1.12225
ShortRL/StdHeuristic                     0
TotalEnvSteps                       644000
----------------------------------  ---------------
2021-05-22 01:49:00 | [online_train] epoch #161 | Saving snapshot...
2021-05-22 01:49:00 | [online_train] epoch #161 | Saved
2021-05-22 01:49:00 | [online_train] epoch #161 | Time 7857.20 s
2021-05-22 01:49:00 | [online_train] epoch #161 | EpochTime 46.42 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00750702
Average/TrainAverageReturn             214.14
Evaluation/AverageDiscountedReturn     146.832
Evaluation/AverageReturn               231.566
Evaluation/Iteration                   161
Evaluation/MaxReturn                   232.991
Evaluation/MinReturn                   229.489
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.11712
Evaluation/TerminationRate               0
Policy/Loss                           -146.898
QF/Qf1Loss                               0.00356396
QF/Qf2Loss                               0.00389469
ReplayBuffer/buffer_size            648000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.159781
ShortRL/RewardScale                      1.12434
ShortRL/StdHeuristic                     0
TotalEnvSteps                       648000
----------------------------------  ---------------
2021-05-22 01:49:47 | [online_train] epoch #162 | Saving snapshot...
2021-05-22 01:49:47 | [online_train] epoch #162 | Saved
2021-05-22 01:49:47 | [online_train] epoch #162 | Time 7904.36 s
2021-05-22 01:49:47 | [online_train] epoch #162 | EpochTime 47.15 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00721881
Average/TrainAverageReturn             214.17
Evaluation/AverageDiscountedReturn     136.697
Evaluation/AverageReturn               205.003
Evaluation/Iteration                   162
Evaluation/MaxReturn                   206.46
Evaluation/MinReturn                   203.583
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.03232
Evaluation/TerminationRate               0
Policy/Loss                           -147.682
QF/Qf1Loss                               0.00334536
QF/Qf2Loss                               0.00601605
ReplayBuffer/buffer_size            652000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.160288
ShortRL/RewardScale                      1.1259
ShortRL/StdHeuristic                     0
TotalEnvSteps                       652000
----------------------------------  ---------------
2021-05-22 01:50:33 | [online_train] epoch #163 | Saving snapshot...
2021-05-22 01:50:33 | [online_train] epoch #163 | Saved
2021-05-22 01:50:33 | [online_train] epoch #163 | Time 7950.76 s
2021-05-22 01:50:33 | [online_train] epoch #163 | EpochTime 46.40 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0069235
Average/TrainAverageReturn             214.313
Evaluation/AverageDiscountedReturn     137.338
Evaluation/AverageReturn               205.72
Evaluation/Iteration                   163
Evaluation/MaxReturn                   213.119
Evaluation/MinReturn                   203.029
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.69844
Evaluation/TerminationRate               0
Policy/Loss                           -148.612
QF/Qf1Loss                               0.00519165
QF/Qf2Loss                               0.00498811
ReplayBuffer/buffer_size            656000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.160656
ShortRL/RewardScale                      1.12748
ShortRL/StdHeuristic                     0
TotalEnvSteps                       656000
----------------------------------  ---------------
2021-05-22 01:51:20 | [online_train] epoch #164 | Saving snapshot...
2021-05-22 01:51:20 | [online_train] epoch #164 | Saved
2021-05-22 01:51:20 | [online_train] epoch #164 | Time 7997.49 s
2021-05-22 01:51:20 | [online_train] epoch #164 | EpochTime 46.72 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00727808
Average/TrainAverageReturn             214.364
Evaluation/AverageDiscountedReturn     136.396
Evaluation/AverageReturn               203.837
Evaluation/Iteration                   164
Evaluation/MaxReturn                   208.769
Evaluation/MinReturn                   201.256
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.49899
Evaluation/TerminationRate               0
Policy/Loss                           -148.701
QF/Qf1Loss                               0.00949234
QF/Qf2Loss                               0.00574172
ReplayBuffer/buffer_size            660000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.161082
ShortRL/RewardScale                      1.1291
ShortRL/StdHeuristic                     0
TotalEnvSteps                       660000
----------------------------------  ---------------
2021-05-22 01:52:06 | [online_train] epoch #165 | Saving snapshot...
2021-05-22 01:52:06 | [online_train] epoch #165 | Saved
2021-05-22 01:52:06 | [online_train] epoch #165 | Time 8043.93 s
2021-05-22 01:52:06 | [online_train] epoch #165 | EpochTime 46.43 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00705107
Average/TrainAverageReturn             213.866
Evaluation/AverageDiscountedReturn     141.606
Evaluation/AverageReturn               217.783
Evaluation/Iteration                   165
Evaluation/MaxReturn                   221.48
Evaluation/MinReturn                   215.556
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.55685
Evaluation/TerminationRate               0
Policy/Loss                           -147.038
QF/Qf1Loss                               0.004582
QF/Qf2Loss                               0.00443298
ReplayBuffer/buffer_size            664000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.161411
ShortRL/RewardScale                      1.13026
ShortRL/StdHeuristic                     0
TotalEnvSteps                       664000
----------------------------------  ---------------
2021-05-22 01:52:53 | [online_train] epoch #166 | Saving snapshot...
2021-05-22 01:52:53 | [online_train] epoch #166 | Saved
2021-05-22 01:52:53 | [online_train] epoch #166 | Time 8090.59 s
2021-05-22 01:52:53 | [online_train] epoch #166 | EpochTime 46.65 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00760489
Average/TrainAverageReturn             213.808
Evaluation/AverageDiscountedReturn     147.996
Evaluation/AverageReturn               233.733
Evaluation/Iteration                   166
Evaluation/MaxReturn                   234.254
Evaluation/MinReturn                   232.983
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.440491
Evaluation/TerminationRate               0
Policy/Loss                           -149.097
QF/Qf1Loss                               0.00536621
QF/Qf2Loss                               0.00463852
ReplayBuffer/buffer_size            668000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.161892
ShortRL/RewardScale                      1.13248
ShortRL/StdHeuristic                     0
TotalEnvSteps                       668000
----------------------------------  ---------------
2021-05-22 01:53:40 | [online_train] epoch #167 | Saving snapshot...
2021-05-22 01:53:40 | [online_train] epoch #167 | Saved
2021-05-22 01:53:40 | [online_train] epoch #167 | Time 8137.12 s
2021-05-22 01:53:40 | [online_train] epoch #167 | EpochTime 46.52 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00785581
Average/TrainAverageReturn             214.364
Evaluation/AverageDiscountedReturn     143.175
Evaluation/AverageReturn               226.472
Evaluation/Iteration                   167
Evaluation/MaxReturn                   227.748
Evaluation/MinReturn                   225.023
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.936027
Evaluation/TerminationRate               0
Policy/Loss                           -148.695
QF/Qf1Loss                               0.00732353
QF/Qf2Loss                               0.00544572
ReplayBuffer/buffer_size            672000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.1624
ShortRL/RewardScale                      1.13424
ShortRL/StdHeuristic                     0
TotalEnvSteps                       672000
----------------------------------  ---------------
2021-05-22 01:54:26 | [online_train] epoch #168 | Saving snapshot...
2021-05-22 01:54:26 | [online_train] epoch #168 | Saved
2021-05-22 01:54:26 | [online_train] epoch #168 | Time 8183.32 s
2021-05-22 01:54:26 | [online_train] epoch #168 | EpochTime 46.20 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00763875
Average/TrainAverageReturn             214.464
Evaluation/AverageDiscountedReturn     140.88
Evaluation/AverageReturn               220.069
Evaluation/Iteration                   168
Evaluation/MaxReturn                   221.542
Evaluation/MinReturn                   218.168
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.09742
Evaluation/TerminationRate               0
Policy/Loss                           -148.469
QF/Qf1Loss                               0.00651741
QF/Qf2Loss                               0.00858949
ReplayBuffer/buffer_size            676000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.162863
ShortRL/RewardScale                      1.13597
ShortRL/StdHeuristic                     0
TotalEnvSteps                       676000
----------------------------------  ---------------
2021-05-22 01:55:12 | [online_train] epoch #169 | Saving snapshot...
2021-05-22 01:55:12 | [online_train] epoch #169 | Saved
2021-05-22 01:55:12 | [online_train] epoch #169 | Time 8229.82 s
2021-05-22 01:55:12 | [online_train] epoch #169 | EpochTime 46.50 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00736825
Average/TrainAverageReturn             214.496
Evaluation/AverageDiscountedReturn     136.327
Evaluation/AverageReturn               203.908
Evaluation/Iteration                   169
Evaluation/MaxReturn                   206.753
Evaluation/MinReturn                   201.672
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.71175
Evaluation/TerminationRate               0
Policy/Loss                           -149.45
QF/Qf1Loss                               0.00367824
QF/Qf2Loss                               0.0052514
ReplayBuffer/buffer_size            680000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.163302
ShortRL/RewardScale                      1.13798
ShortRL/StdHeuristic                     0
TotalEnvSteps                       680000
----------------------------------  ---------------
2021-05-22 01:55:59 | [online_train] epoch #170 | Saving snapshot...
2021-05-22 01:55:59 | [online_train] epoch #170 | Saved
2021-05-22 01:55:59 | [online_train] epoch #170 | Time 8276.53 s
2021-05-22 01:55:59 | [online_train] epoch #170 | EpochTime 46.70 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00753005
Average/TrainAverageReturn             214.067
Evaluation/AverageDiscountedReturn     139.245
Evaluation/AverageReturn               207.99
Evaluation/Iteration                   170
Evaluation/MaxReturn                   209.245
Evaluation/MinReturn                   206.998
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.720315
Evaluation/TerminationRate               0
Policy/Loss                           -150.886
QF/Qf1Loss                               0.00346633
QF/Qf2Loss                               0.00297891
ReplayBuffer/buffer_size            684000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.163671
ShortRL/RewardScale                      1.13929
ShortRL/StdHeuristic                     0
TotalEnvSteps                       684000
----------------------------------  ---------------
2021-05-22 01:56:45 | [online_train] epoch #171 | Saving snapshot...
2021-05-22 01:56:45 | [online_train] epoch #171 | Saved
2021-05-22 01:56:45 | [online_train] epoch #171 | Time 8322.76 s
2021-05-22 01:56:45 | [online_train] epoch #171 | EpochTime 46.22 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00752221
Average/TrainAverageReturn             214.373
Evaluation/AverageDiscountedReturn     139.359
Evaluation/AverageReturn               209.197
Evaluation/Iteration                   171
Evaluation/MaxReturn                   210.726
Evaluation/MinReturn                   207.669
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.957255
Evaluation/TerminationRate               0
Policy/Loss                           -149.908
QF/Qf1Loss                               0.00272973
QF/Qf2Loss                               0.00579961
ReplayBuffer/buffer_size            688000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.164046
ShortRL/RewardScale                      1.14084
ShortRL/StdHeuristic                     0
TotalEnvSteps                       688000
----------------------------------  ---------------
2021-05-22 01:57:32 | [online_train] epoch #172 | Saving snapshot...
2021-05-22 01:57:32 | [online_train] epoch #172 | Saved
2021-05-22 01:57:32 | [online_train] epoch #172 | Time 8369.56 s
2021-05-22 01:57:32 | [online_train] epoch #172 | EpochTime 46.80 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00779143
Average/TrainAverageReturn             214.208
Evaluation/AverageDiscountedReturn     136.706
Evaluation/AverageReturn               204.884
Evaluation/Iteration                   172
Evaluation/MaxReturn                   209.389
Evaluation/MinReturn                   201.734
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.23433
Evaluation/TerminationRate               0
Policy/Loss                           -149.791
QF/Qf1Loss                               0.0029792
QF/Qf2Loss                               0.00359125
ReplayBuffer/buffer_size            692000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.164461
ShortRL/RewardScale                      1.14262
ShortRL/StdHeuristic                     0
TotalEnvSteps                       692000
----------------------------------  ---------------
2021-05-22 01:58:19 | [online_train] epoch #173 | Saving snapshot...
2021-05-22 01:58:19 | [online_train] epoch #173 | Saved
2021-05-22 01:58:19 | [online_train] epoch #173 | Time 8416.23 s
2021-05-22 01:58:19 | [online_train] epoch #173 | EpochTime 46.66 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00739567
Average/TrainAverageReturn             214.038
Evaluation/AverageDiscountedReturn     147.685
Evaluation/AverageReturn               233.269
Evaluation/Iteration                   173
Evaluation/MaxReturn                   234.626
Evaluation/MinReturn                   231.455
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.987267
Evaluation/TerminationRate               0
Policy/Loss                           -153.038
QF/Qf1Loss                               0.0149382
QF/Qf2Loss                               0.00527608
ReplayBuffer/buffer_size            696000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.164811
ShortRL/RewardScale                      1.1444
ShortRL/StdHeuristic                     0
TotalEnvSteps                       696000
----------------------------------  ---------------
2021-05-22 01:59:05 | [online_train] epoch #174 | Saving snapshot...
2021-05-22 01:59:05 | [online_train] epoch #174 | Saved
2021-05-22 01:59:05 | [online_train] epoch #174 | Time 8462.59 s
2021-05-22 01:59:05 | [online_train] epoch #174 | EpochTime 46.36 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00736889
Average/TrainAverageReturn             214.72
Evaluation/AverageDiscountedReturn     145.911
Evaluation/AverageReturn               229.896
Evaluation/Iteration                   174
Evaluation/MaxReturn                   230.776
Evaluation/MinReturn                   229.051
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.532349
Evaluation/TerminationRate               0
Policy/Loss                           -154.233
QF/Qf1Loss                               0.00513824
QF/Qf2Loss                               0.00445254
ReplayBuffer/buffer_size            700000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.16526
ShortRL/RewardScale                      1.14612
ShortRL/StdHeuristic                     0
TotalEnvSteps                       700000
----------------------------------  ---------------
2021-05-22 01:59:51 | [online_train] epoch #175 | Saving snapshot...
2021-05-22 01:59:51 | [online_train] epoch #175 | Saved
2021-05-22 01:59:51 | [online_train] epoch #175 | Time 8508.96 s
2021-05-22 01:59:51 | [online_train] epoch #175 | EpochTime 46.36 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00729138
Average/TrainAverageReturn             215.212
Evaluation/AverageDiscountedReturn     146.375
Evaluation/AverageReturn               231.781
Evaluation/Iteration                   175
Evaluation/MaxReturn                   233.385
Evaluation/MinReturn                   230.11
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.01995
Evaluation/TerminationRate               0
Policy/Loss                           -155.178
QF/Qf1Loss                               0.00423892
QF/Qf2Loss                               0.0040121
ReplayBuffer/buffer_size            704000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.165662
ShortRL/RewardScale                      1.14795
ShortRL/StdHeuristic                     0
TotalEnvSteps                       704000
----------------------------------  ---------------
2021-05-22 02:01:03 | [online_train] epoch #176 | Saving snapshot...
2021-05-22 02:01:03 | [online_train] epoch #176 | Saved
2021-05-22 02:01:03 | [online_train] epoch #176 | Time 8580.37 s
2021-05-22 02:01:03 | [online_train] epoch #176 | EpochTime 71.41 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00761222
Average/TrainAverageReturn             215.588
Evaluation/AverageDiscountedReturn     140.53
Evaluation/AverageReturn               213.832
Evaluation/Iteration                   176
Evaluation/MaxReturn                   214.757
Evaluation/MinReturn                   211.668
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.949433
Evaluation/TerminationRate               0
Policy/Loss                           -155.043
QF/Qf1Loss                               0.0114167
QF/Qf2Loss                               0.00561667
ReplayBuffer/buffer_size            708000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.166063
ShortRL/RewardScale                      1.14972
ShortRL/StdHeuristic                     0
TotalEnvSteps                       708000
----------------------------------  ---------------
2021-05-22 02:01:49 | [online_train] epoch #177 | Saving snapshot...
2021-05-22 02:01:49 | [online_train] epoch #177 | Saved
2021-05-22 02:01:49 | [online_train] epoch #177 | Time 8626.87 s
2021-05-22 02:01:49 | [online_train] epoch #177 | EpochTime 46.49 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00759313
Average/TrainAverageReturn             215.656
Evaluation/AverageDiscountedReturn     139.891
Evaluation/AverageReturn               212.75
Evaluation/Iteration                   177
Evaluation/MaxReturn                   219.435
Evaluation/MinReturn                   208.28
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.8992
Evaluation/TerminationRate               0
Policy/Loss                           -153.348
QF/Qf1Loss                               0.00351587
QF/Qf2Loss                               0.00329984
ReplayBuffer/buffer_size            712000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.166496
ShortRL/RewardScale                      1.15156
ShortRL/StdHeuristic                     0
TotalEnvSteps                       712000
----------------------------------  ---------------
2021-05-22 02:02:36 | [online_train] epoch #178 | Saving snapshot...
2021-05-22 02:02:36 | [online_train] epoch #178 | Saved
2021-05-22 02:02:36 | [online_train] epoch #178 | Time 8673.11 s
2021-05-22 02:02:36 | [online_train] epoch #178 | EpochTime 46.23 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00774303
Average/TrainAverageReturn             215.682
Evaluation/AverageDiscountedReturn     138.517
Evaluation/AverageReturn               207.662
Evaluation/Iteration                   178
Evaluation/MaxReturn                   209.879
Evaluation/MinReturn                   205.956
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.34749
Evaluation/TerminationRate               0
Policy/Loss                           -153.54
QF/Qf1Loss                               0.00316105
QF/Qf2Loss                               0.00427144
ReplayBuffer/buffer_size            716000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.16692
ShortRL/RewardScale                      1.15334
ShortRL/StdHeuristic                     0
TotalEnvSteps                       716000
----------------------------------  ---------------
2021-05-22 02:03:22 | [online_train] epoch #179 | Saving snapshot...
2021-05-22 02:03:22 | [online_train] epoch #179 | Saved
2021-05-22 02:03:22 | [online_train] epoch #179 | Time 8719.32 s
2021-05-22 02:03:22 | [online_train] epoch #179 | EpochTime 46.21 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00772825
Average/TrainAverageReturn             215.37
Evaluation/AverageDiscountedReturn     139.794
Evaluation/AverageReturn               215.251
Evaluation/Iteration                   179
Evaluation/MaxReturn                   220.204
Evaluation/MinReturn                   205.442
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     4.30907
Evaluation/TerminationRate               0
Policy/Loss                           -155.002
QF/Qf1Loss                               0.00560019
QF/Qf2Loss                               0.00524924
ReplayBuffer/buffer_size            720000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.167233
ShortRL/RewardScale                      1.15521
ShortRL/StdHeuristic                     0
TotalEnvSteps                       720000
----------------------------------  ---------------
2021-05-22 02:04:08 | [online_train] epoch #180 | Saving snapshot...
2021-05-22 02:04:08 | [online_train] epoch #180 | Saved
2021-05-22 02:04:08 | [online_train] epoch #180 | Time 8765.86 s
2021-05-22 02:04:08 | [online_train] epoch #180 | EpochTime 46.53 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00785259
Average/TrainAverageReturn             215.158
Evaluation/AverageDiscountedReturn     138.946
Evaluation/AverageReturn               208.273
Evaluation/Iteration                   180
Evaluation/MaxReturn                   214.237
Evaluation/MinReturn                   204.532
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.86695
Evaluation/TerminationRate               0
Policy/Loss                           -155.049
QF/Qf1Loss                               0.00765524
QF/Qf2Loss                               0.00423327
ReplayBuffer/buffer_size            724000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.167489
ShortRL/RewardScale                      1.15727
ShortRL/StdHeuristic                     0
TotalEnvSteps                       724000
----------------------------------  ---------------
2021-05-22 02:04:56 | [online_train] epoch #181 | Saving snapshot...
2021-05-22 02:04:56 | [online_train] epoch #181 | Saved
2021-05-22 02:04:56 | [online_train] epoch #181 | Time 8813.60 s
2021-05-22 02:04:56 | [online_train] epoch #181 | EpochTime 47.73 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00815445
Average/TrainAverageReturn             215.636
Evaluation/AverageDiscountedReturn     138.254
Evaluation/AverageReturn               208.174
Evaluation/Iteration                   181
Evaluation/MaxReturn                   209.916
Evaluation/MinReturn                   207.061
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     0.812323
Evaluation/TerminationRate               0
Policy/Loss                           -155.28
QF/Qf1Loss                               0.00922254
QF/Qf2Loss                               0.00238525
ReplayBuffer/buffer_size            728000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.167871
ShortRL/RewardScale                      1.1596
ShortRL/StdHeuristic                     0
TotalEnvSteps                       728000
----------------------------------  ---------------
2021-05-22 02:05:43 | [online_train] epoch #182 | Saving snapshot...
2021-05-22 02:05:43 | [online_train] epoch #182 | Saved
2021-05-22 02:05:43 | [online_train] epoch #182 | Time 8860.65 s
2021-05-22 02:05:43 | [online_train] epoch #182 | EpochTime 47.05 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00774247
Average/TrainAverageReturn             215.676
Evaluation/AverageDiscountedReturn     143.027
Evaluation/AverageReturn               226.055
Evaluation/Iteration                   182
Evaluation/MaxReturn                   229.709
Evaluation/MinReturn                   222.611
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.20044
Evaluation/TerminationRate               0
Policy/Loss                           -153.933
QF/Qf1Loss                               0.00477555
QF/Qf2Loss                               0.00629555
ReplayBuffer/buffer_size            732000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.168294
ShortRL/RewardScale                      1.1623
ShortRL/StdHeuristic                     0
TotalEnvSteps                       732000
----------------------------------  ---------------
2021-05-22 02:06:30 | [online_train] epoch #183 | Saving snapshot...
2021-05-22 02:06:30 | [online_train] epoch #183 | Saved
2021-05-22 02:06:30 | [online_train] epoch #183 | Time 8907.35 s
2021-05-22 02:06:30 | [online_train] epoch #183 | EpochTime 46.69 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00765629
Average/TrainAverageReturn             215.503
Evaluation/AverageDiscountedReturn     137.255
Evaluation/AverageReturn               206.737
Evaluation/Iteration                   183
Evaluation/MaxReturn                   209.726
Evaluation/MinReturn                   204.299
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.82771
Evaluation/TerminationRate               0
Policy/Loss                           -157.557
QF/Qf1Loss                               0.00253082
QF/Qf2Loss                               0.00228544
ReplayBuffer/buffer_size            736000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.168683
ShortRL/RewardScale                      1.1657
ShortRL/StdHeuristic                     0
TotalEnvSteps                       736000
----------------------------------  ---------------
2021-05-22 02:07:16 | [online_train] epoch #184 | Saving snapshot...
2021-05-22 02:07:16 | [online_train] epoch #184 | Saved
2021-05-22 02:07:16 | [online_train] epoch #184 | Time 8953.78 s
2021-05-22 02:07:16 | [online_train] epoch #184 | EpochTime 46.42 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00717953
Average/TrainAverageReturn             215.633
Evaluation/AverageDiscountedReturn     148.571
Evaluation/AverageReturn               237.698
Evaluation/Iteration                   184
Evaluation/MaxReturn                   239.332
Evaluation/MinReturn                   235.596
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.13176
Evaluation/TerminationRate               0
Policy/Loss                           -155.27
QF/Qf1Loss                               0.00562685
QF/Qf2Loss                               0.00923678
ReplayBuffer/buffer_size            740000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.169106
ShortRL/RewardScale                      1.16721
ShortRL/StdHeuristic                     0
TotalEnvSteps                       740000
----------------------------------  ---------------
2021-05-22 02:08:02 | [online_train] epoch #185 | Saving snapshot...
2021-05-22 02:08:02 | [online_train] epoch #185 | Saved
2021-05-22 02:08:02 | [online_train] epoch #185 | Time 8999.79 s
2021-05-22 02:08:02 | [online_train] epoch #185 | EpochTime 46.00 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00693498
Average/TrainAverageReturn             216.16
Evaluation/AverageDiscountedReturn     141.406
Evaluation/AverageReturn               216.997
Evaluation/Iteration                   185
Evaluation/MaxReturn                   221.491
Evaluation/MinReturn                   212.248
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.04079
Evaluation/TerminationRate               0
Policy/Loss                           -157.318
QF/Qf1Loss                               0.00474731
QF/Qf2Loss                               0.00221434
ReplayBuffer/buffer_size            744000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.169558
ShortRL/RewardScale                      1.1702
ShortRL/StdHeuristic                     0
TotalEnvSteps                       744000
----------------------------------  ---------------
2021-05-22 02:08:49 | [online_train] epoch #186 | Saving snapshot...
2021-05-22 02:08:49 | [online_train] epoch #186 | Saved
2021-05-22 02:08:49 | [online_train] epoch #186 | Time 9046.81 s
2021-05-22 02:08:49 | [online_train] epoch #186 | EpochTime 47.02 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00709508
Average/TrainAverageReturn             216.003
Evaluation/AverageDiscountedReturn     142.81
Evaluation/AverageReturn               220.189
Evaluation/Iteration                   186
Evaluation/MaxReturn                   225.008
Evaluation/MinReturn                   215.387
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.39597
Evaluation/TerminationRate               0
Policy/Loss                           -157.961
QF/Qf1Loss                               0.00144136
QF/Qf2Loss                               0.00362514
ReplayBuffer/buffer_size            748000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.169869
ShortRL/RewardScale                      1.17252
ShortRL/StdHeuristic                     0
TotalEnvSteps                       748000
----------------------------------  ---------------
2021-05-22 02:09:36 | [online_train] epoch #187 | Saving snapshot...
2021-05-22 02:09:36 | [online_train] epoch #187 | Saved
2021-05-22 02:09:36 | [online_train] epoch #187 | Time 9093.45 s
2021-05-22 02:09:36 | [online_train] epoch #187 | EpochTime 46.64 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00727031
Average/TrainAverageReturn             215.823
Evaluation/AverageDiscountedReturn     141.861
Evaluation/AverageReturn               214.193
Evaluation/Iteration                   187
Evaluation/MaxReturn                   225.232
Evaluation/MinReturn                   210.797
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.93072
Evaluation/TerminationRate               0
Policy/Loss                           -157.129
QF/Qf1Loss                               0.00278609
QF/Qf2Loss                               0.00290999
ReplayBuffer/buffer_size            752000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.170189
ShortRL/RewardScale                      1.17393
ShortRL/StdHeuristic                     0
TotalEnvSteps                       752000
----------------------------------  ---------------
2021-05-22 02:10:22 | [online_train] epoch #188 | Saving snapshot...
2021-05-22 02:10:22 | [online_train] epoch #188 | Saved
2021-05-22 02:10:22 | [online_train] epoch #188 | Time 9140.01 s
2021-05-22 02:10:22 | [online_train] epoch #188 | EpochTime 46.55 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00797912
Average/TrainAverageReturn             215.926
Evaluation/AverageDiscountedReturn     142.586
Evaluation/AverageReturn               220.957
Evaluation/Iteration                   188
Evaluation/MaxReturn                   223.703
Evaluation/MinReturn                   217.518
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.81094
Evaluation/TerminationRate               0
Policy/Loss                           -156.763
QF/Qf1Loss                               0.00238525
QF/Qf2Loss                               0.00414702
ReplayBuffer/buffer_size            756000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.170507
ShortRL/RewardScale                      1.17535
ShortRL/StdHeuristic                     0
TotalEnvSteps                       756000
----------------------------------  ---------------
2021-05-22 02:11:09 | [online_train] epoch #189 | Saving snapshot...
2021-05-22 02:11:09 | [online_train] epoch #189 | Saved
2021-05-22 02:11:09 | [online_train] epoch #189 | Time 9186.75 s
2021-05-22 02:11:09 | [online_train] epoch #189 | EpochTime 46.74 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00748624
Average/TrainAverageReturn             215.578
Evaluation/AverageDiscountedReturn     140.329
Evaluation/AverageReturn               211.581
Evaluation/Iteration                   189
Evaluation/MaxReturn                   216.884
Evaluation/MinReturn                   207.926
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.12392
Evaluation/TerminationRate               0
Policy/Loss                           -158.2
QF/Qf1Loss                               0.00457383
QF/Qf2Loss                               0.00386574
ReplayBuffer/buffer_size            760000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.170812
ShortRL/RewardScale                      1.17655
ShortRL/StdHeuristic                     0
TotalEnvSteps                       760000
----------------------------------  ---------------
2021-05-22 02:11:56 | [online_train] epoch #190 | Saving snapshot...
2021-05-22 02:11:56 | [online_train] epoch #190 | Saved
2021-05-22 02:11:56 | [online_train] epoch #190 | Time 9233.30 s
2021-05-22 02:11:56 | [online_train] epoch #190 | EpochTime 46.54 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00764237
Average/TrainAverageReturn             215.314
Evaluation/AverageDiscountedReturn     150.299
Evaluation/AverageReturn               237.605
Evaluation/Iteration                   190
Evaluation/MaxReturn                   241.724
Evaluation/MinReturn                   230.556
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.89242
Evaluation/TerminationRate               0
Policy/Loss                           -159.706
QF/Qf1Loss                               0.00336748
QF/Qf2Loss                               0.00255921
ReplayBuffer/buffer_size            764000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.171108
ShortRL/RewardScale                      1.17786
ShortRL/StdHeuristic                     0
TotalEnvSteps                       764000
----------------------------------  ---------------
2021-05-22 02:12:42 | [online_train] epoch #191 | Saving snapshot...
2021-05-22 02:12:42 | [online_train] epoch #191 | Saved
2021-05-22 02:12:42 | [online_train] epoch #191 | Time 9279.12 s
2021-05-22 02:12:42 | [online_train] epoch #191 | EpochTime 45.82 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00787814
Average/TrainAverageReturn             215.394
Evaluation/AverageDiscountedReturn     143.996
Evaluation/AverageReturn               221.608
Evaluation/Iteration                   191
Evaluation/MaxReturn                   226.561
Evaluation/MinReturn                   216.601
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.735
Evaluation/TerminationRate               0
Policy/Loss                           -156.975
QF/Qf1Loss                               0.00406877
QF/Qf2Loss                               0.00274526
ReplayBuffer/buffer_size            768000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.171522
ShortRL/RewardScale                      1.17913
ShortRL/StdHeuristic                     0
TotalEnvSteps                       768000
----------------------------------  ---------------
2021-05-22 02:13:28 | [online_train] epoch #192 | Saving snapshot...
2021-05-22 02:13:28 | [online_train] epoch #192 | Saved
2021-05-22 02:13:28 | [online_train] epoch #192 | Time 9325.21 s
2021-05-22 02:13:28 | [online_train] epoch #192 | EpochTime 46.08 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00785477
Average/TrainAverageReturn             215.767
Evaluation/AverageDiscountedReturn     139.821
Evaluation/AverageReturn               210.421
Evaluation/Iteration                   192
Evaluation/MaxReturn                   218.702
Evaluation/MinReturn                   207.533
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.9971
Evaluation/TerminationRate               0
Policy/Loss                           -159.534
QF/Qf1Loss                               0.00233377
QF/Qf2Loss                               0.00310116
ReplayBuffer/buffer_size            772000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.171969
ShortRL/RewardScale                      1.18053
ShortRL/StdHeuristic                     0
TotalEnvSteps                       772000
----------------------------------  ---------------
2021-05-22 02:14:14 | [online_train] epoch #193 | Saving snapshot...
2021-05-22 02:14:14 | [online_train] epoch #193 | Saved
2021-05-22 02:14:14 | [online_train] epoch #193 | Time 9371.57 s
2021-05-22 02:14:14 | [online_train] epoch #193 | EpochTime 46.36 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00762271
Average/TrainAverageReturn             216.352
Evaluation/AverageDiscountedReturn     145.986
Evaluation/AverageReturn               228.748
Evaluation/Iteration                   193
Evaluation/MaxReturn                   233.942
Evaluation/MinReturn                   219.427
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.88357
Evaluation/TerminationRate               0
Policy/Loss                           -159.151
QF/Qf1Loss                               0.00359074
QF/Qf2Loss                               0.00282165
ReplayBuffer/buffer_size            776000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.172341
ShortRL/RewardScale                      1.18159
ShortRL/StdHeuristic                     0
TotalEnvSteps                       776000
----------------------------------  ---------------
2021-05-22 02:15:01 | [online_train] epoch #194 | Saving snapshot...
2021-05-22 02:15:01 | [online_train] epoch #194 | Saved
2021-05-22 02:15:01 | [online_train] epoch #194 | Time 9418.15 s
2021-05-22 02:15:01 | [online_train] epoch #194 | EpochTime 46.58 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00756281
Average/TrainAverageReturn             216.563
Evaluation/AverageDiscountedReturn     140.055
Evaluation/AverageReturn               211.78
Evaluation/Iteration                   194
Evaluation/MaxReturn                   216.735
Evaluation/MinReturn                   208.332
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.54147
Evaluation/TerminationRate               0
Policy/Loss                           -160.056
QF/Qf1Loss                               0.00392167
QF/Qf2Loss                               0.00449629
ReplayBuffer/buffer_size            780000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.172681
ShortRL/RewardScale                      1.18247
ShortRL/StdHeuristic                     0
TotalEnvSteps                       780000
----------------------------------  ---------------
2021-05-22 02:15:55 | [online_train] epoch #195 | Saving snapshot...
2021-05-22 02:15:55 | [online_train] epoch #195 | Saved
2021-05-22 02:15:55 | [online_train] epoch #195 | Time 9472.67 s
2021-05-22 02:15:55 | [online_train] epoch #195 | EpochTime 54.51 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00784175
Average/TrainAverageReturn             216.973
Evaluation/AverageDiscountedReturn     143.043
Evaluation/AverageReturn               218.997
Evaluation/Iteration                   195
Evaluation/MaxReturn                   227.8
Evaluation/MinReturn                   214.876
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     4.58137
Evaluation/TerminationRate               0
Policy/Loss                           -160.795
QF/Qf1Loss                               0.00700994
QF/Qf2Loss                               0.00525058
ReplayBuffer/buffer_size            784000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.17298
ShortRL/RewardScale                      1.18364
ShortRL/StdHeuristic                     0
TotalEnvSteps                       784000
----------------------------------  ---------------
2021-05-22 02:16:41 | [online_train] epoch #196 | Saving snapshot...
2021-05-22 02:16:41 | [online_train] epoch #196 | Saved
2021-05-22 02:16:41 | [online_train] epoch #196 | Time 9518.63 s
2021-05-22 02:16:41 | [online_train] epoch #196 | EpochTime 45.95 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00769737
Average/TrainAverageReturn             217.001
Evaluation/AverageDiscountedReturn     142.733
Evaluation/AverageReturn               216.007
Evaluation/Iteration                   196
Evaluation/MaxReturn                   221.49
Evaluation/MinReturn                   211.999
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.54937
Evaluation/TerminationRate               0
Policy/Loss                           -160.027
QF/Qf1Loss                               0.00427437
QF/Qf2Loss                               0.00358524
ReplayBuffer/buffer_size            788000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.173332
ShortRL/RewardScale                      1.18454
ShortRL/StdHeuristic                     0
TotalEnvSteps                       788000
----------------------------------  ---------------
2021-05-22 02:17:27 | [online_train] epoch #197 | Saving snapshot...
2021-05-22 02:17:27 | [online_train] epoch #197 | Saved
2021-05-22 02:17:27 | [online_train] epoch #197 | Time 9564.75 s
2021-05-22 02:17:27 | [online_train] epoch #197 | EpochTime 46.11 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00738842
Average/TrainAverageReturn             217.144
Evaluation/AverageDiscountedReturn     148.688
Evaluation/AverageReturn               232.919
Evaluation/Iteration                   197
Evaluation/MaxReturn                   237.039
Evaluation/MinReturn                   224.568
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     3.57829
Evaluation/TerminationRate               0
Policy/Loss                           -161.496
QF/Qf1Loss                               0.00869237
QF/Qf2Loss                               0.0041564
ReplayBuffer/buffer_size            792000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.173734
ShortRL/RewardScale                      1.18568
ShortRL/StdHeuristic                     0
TotalEnvSteps                       792000
----------------------------------  ---------------
2021-05-22 02:18:13 | [online_train] epoch #198 | Saving snapshot...
2021-05-22 02:18:13 | [online_train] epoch #198 | Saved
2021-05-22 02:18:13 | [online_train] epoch #198 | Time 9610.42 s
2021-05-22 02:18:13 | [online_train] epoch #198 | EpochTime 45.67 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.0074432
Average/TrainAverageReturn             217.646
Evaluation/AverageDiscountedReturn     151.324
Evaluation/AverageReturn               238.81
Evaluation/Iteration                   198
Evaluation/MaxReturn                   240.84
Evaluation/MinReturn                   232.584
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     2.53607
Evaluation/TerminationRate               0
Policy/Loss                           -161.381
QF/Qf1Loss                               0.00289212
QF/Qf2Loss                               0.00332726
ReplayBuffer/buffer_size            796000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.174176
ShortRL/RewardScale                      1.18705
ShortRL/StdHeuristic                     0
TotalEnvSteps                       796000
----------------------------------  ---------------
2021-05-22 02:18:59 | [online_train] epoch #199 | Saving snapshot...
2021-05-22 02:18:59 | [online_train] epoch #199 | Saved
2021-05-22 02:18:59 | [online_train] epoch #199 | Time 9656.63 s
2021-05-22 02:18:59 | [online_train] epoch #199 | EpochTime 46.20 s
----------------------------------  ---------------
AlphaTemperature/mean                    0.00791353
Average/TrainAverageReturn             218.084
Evaluation/AverageDiscountedReturn     143.174
Evaluation/AverageReturn               215.979
Evaluation/Iteration                   199
Evaluation/MaxReturn                   218.16
Evaluation/MinReturn                   213.804
Evaluation/NumEpisodes                  10
Evaluation/StdReturn                     1.3789
Evaluation/TerminationRate               0
Policy/Loss                           -162.338
QF/Qf1Loss                               0.00444608
QF/Qf2Loss                               0.00405099
ReplayBuffer/buffer_size            800000
ShortRL/Discount0                        0.999
ShortRL/GuidanceDiscount                 0.999
ShortRL/Lambda                           1
ShortRL/MaxHeuristic                     0
ShortRL/MeanHeuristic                    0
ShortRL/MinHeuristic                     0
ShortRL/RewardBias                       0.174582
ShortRL/RewardScale                      1.18803
ShortRL/StdHeuristic                     0
TotalEnvSteps                       800000
----------------------------------  ---------------
